# Advanced AI Agents Module

Enterprise-grade orchestration patterns for LangGraph-based AI agents.

## Overview

This module extends the base AI agent with advanced orchestration capabilities:

- **Plan-and-Execute**: LLM generates structured plans, executor follows them
- **Parallel Execution**: Fan-out/fan-in pattern for concurrent task execution
- **Dynamic Routing**: LLM-based runtime routing decisions
- **Result Aggregation**: Intelligent synthesis of multi-source results
- **State Management**: Reducers for safe concurrent state updates

## Quick Start

### 1. Run Parallel Execution Demo

```bash
cd backend
python -m advanced_agents.examples.parallel_demo
```

This demonstrates:
- 3 parallel API calls (weather, FX, crypto)
- Result aggregation
- Performance comparison vs sequential execution

### 2. Use in Your Code

```python
from advanced_agents import AdvancedAgentGraph, create_initial_state
from langchain_openai import ChatOpenAI

# Initialize
llm = ChatOpenAI(model="gpt-4-turbo-preview", ...)
tools = {"weather": weather_tool, "fx_rates": fx_tool, ...}

graph = AdvancedAgentGraph(llm=llm, tools=tools)

# Create state
state = create_initial_state(
    user_id="user_123",
    message="What's the weather in Paris and USD to EUR rate?"
)

# Execute
final_state = await graph.run(state)
print(final_state["final_answer"])
```

### 3. Try API Endpoints

```bash
# Parallel demo
curl -X POST http://localhost:8000/api/advanced/parallel-demo \
  -H "Content-Type: application/json" \
  -d '{"message": "Weather in London, USD to EUR, and Bitcoin price?"}'

# Plan-and-Execute
curl -X POST http://localhost:8000/api/advanced/plan-execute \
  -H "Content-Type: application/json" \
  -d '{"user_id": "user_123", "message": "Find my location and get weather there"}'

# Get capabilities
curl http://localhost:8000/api/advanced/capabilities
```

## Module Structure

```
advanced_agents/
â”œâ”€â”€ __init__.py              # Public API
â”œâ”€â”€ state.py                 # State models & reducers
â”œâ”€â”€ advanced_graph.py        # Main workflow
â”œâ”€â”€ planning/
â”‚   â”œâ”€â”€ planner.py          # LLM-based planning
â”‚   â””â”€â”€ executor.py         # Step execution
â”œâ”€â”€ parallel/
â”‚   â”œâ”€â”€ fan_out.py          # Spawn parallel tasks
â”‚   â””â”€â”€ fan_in.py           # Aggregate results
â”œâ”€â”€ routing/
â”‚   â””â”€â”€ router.py           # Dynamic routing
â”œâ”€â”€ aggregation/
â”‚   â””â”€â”€ aggregator.py       # Result synthesis
â””â”€â”€ examples/
    â””â”€â”€ parallel_demo.py    # Educational demo
```

## Key Concepts

### Plan-and-Execute

Separates "thinking" (planning) from "doing" (execution):

1. **Planner** generates structured JSON plan
2. **Executor** follows plan step-by-step
3. Handles dependencies, retries, failures

**When to use**: Multi-step tasks, dependent operations

### Parallel Execution

Runs independent tasks concurrently:

1. **Fan-Out** spawns parallel branches
2. Each branch executes independently
3. **Fan-In** merges results via reducers

**When to use**: Independent API calls, data gathering

**Performance**: 3 tasks @ 2s each = 2s total (not 6s)

### Dynamic Routing

LLM decides which nodes to execute:

1. Analyzes current state
2. Decides single or multiple nodes
3. Can enable parallel execution

**When to use**: Adaptive workflows, complex decisions

### State Reducers

Safe merging of concurrent state updates:

```python
# Without reducer: Last write wins (data loss!)
# With reducer: All updates merged safely

from typing import Annotated

state_field: Annotated[List[Dict], list_reducer]
```

**When to use**: Any parallel execution

## Examples

### Example 1: Parallel API Calls

```python
# User: "Weather in London, USD to EUR, and Bitcoin price?"

# Result: 3 parallel API calls execute in ~2s
{
  "weather": {"temp": 15, "condition": "cloudy"},
  "fx_rates": {"USD_EUR": 0.85},
  "crypto": {"BTC": 45000}
}
```

### Example 2: Dependent Steps

```python
# User: "Find my location and get weather there"

# Plan:
# Step 1: IP geolocation â†’ city
# Step 2: Weather for ${step_1.city}

# Sequential execution with dependency resolution
```

### Example 3: Dynamic Routing

```python
# User: "What's the weather?"
# Router â†’ single node (weather)

# User: "Weather and exchange rate?"
# Router â†’ parallel nodes (weather + fx)
```

## Performance

### Latency Comparison

| Scenario | Sequential | Parallel | Speedup |
|----------|-----------|----------|---------|
| 3 API calls (2s each) | 6s | 2s | 3x |
| 5 API calls (1.5s each) | 7.5s | 1.5s | 5x |

### Best Practices

1. **Limit Parallelism**: 2-5 tasks max
2. **Use Timeouts**: `timeout_seconds=5.0`
3. **Handle Failures**: Partial results better than none
4. **Cache Results**: Don't repeat expensive operations

## Documentation

- **[ADVANCED_AGENTS.md](../../docs/ADVANCED_AGENTS.md)**: Complete guide with examples
- **[SPECIFICATION.md](../../docs/SPECIFICATION.md)**: Updated project spec
- **Inline Comments**: Every file has educational WHY comments

## Testing

```bash
# Run demo
python -m advanced_agents.examples.parallel_demo

# Run tests (when available)
pytest advanced_agents/tests/
```

## Architecture Principles

All code follows **SOLID principles**:

- âœ… Single Responsibility
- âœ… Open/Closed
- âœ… Liskov Substitution
- âœ… Interface Segregation
- âœ… Dependency Inversion

## Learning Resources

1. Run `parallel_demo.py` and read the output
2. Read inline comments explaining WHY
3. Modify examples to experiment
4. Check `docs/ADVANCED_AGENTS.md` for theory

## Contributing

This is an educational module. When adding features:

1. Follow SOLID principles
2. Add extensive WHY comments
3. Create runnable examples
4. Update documentation

## Version

**Version**: 1.0.0  
**Last Updated**: January 12, 2026  
**Status**: âœ… Production Ready

---

**Happy Learning! ðŸš€**
