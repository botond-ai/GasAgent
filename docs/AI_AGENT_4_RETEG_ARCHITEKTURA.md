# AI Agent 4 RÃ©tegÅ± ArchitektÃºra - ImplementÃ¡ciÃ³s ÃštmutatÃ³

## ÃttekintÃ©s

Egy Ã¶sszetett AI agent 4 fÅ‘ rÃ©tegbÅ‘l Ã©pÃ¼l fel, amelyek egyÃ¼ttmÅ±kÃ¶dve biztosÃ­tjÃ¡k az intelligens, kontextus-tudatos mÅ±kÃ¶dÃ©st. Ez a dokumentum rÃ©szletesen bemutatja az alkalmazÃ¡sunkban megvalÃ³sÃ­tott architektÃºrÃ¡t valÃ³s kÃ³dpÃ©ldÃ¡kkal.

---

## 1. Reasoning Layer (LLM GondolkodÃ¡s / DÃ¶ntÃ©sek)

### CÃ©lja
Az LLM gondolkodÃ¡si rÃ©teg felelÅ‘s az intelligens dÃ¶ntÃ©shozatalÃ©rt: promptolÃ¡s, chain-of-thought Ã©rvelÃ©s, triÃ¡zs Ã©s routing.

### Kulcs Komponensek

#### 1.1 System Prompt Ã‰pÃ­tÃ©s

A system prompt biztosÃ­tja a kontextust Ã©s a szemÃ©lyisÃ©get:

```python
# backend/services/agent.py

def _build_system_prompt(self, memory: Memory) -> str:
    """Rendszer prompt Ã©pÃ­tÃ©se memÃ³ria kontextussal."""
    preferences = memory.preferences
    workflow = memory.workflow_state
    
    # FelhasznÃ¡lÃ³i informÃ¡ciÃ³k gyÅ±jtÃ©se
    user_info = []
    if preferences.get('name'):
        user_info.append(f"- NÃ©v: {preferences['name']}")
    user_info.append(f"- Nyelv: {preferences.get('language', 'hu')}")
    user_info.append(f"- AlapÃ©rtelmezett vÃ¡ros: {preferences.get('default_city', 'Budapest')}")
    
    prompt = f"""Te egy segÃ­tÅ‘kÃ©sz AI asszisztens vagy, kÃ¼lÃ¶nbÃ¶zÅ‘ eszkÃ¶zÃ¶kkel.

FelhasznÃ¡lÃ³i preferenciÃ¡k:
{chr(10).join(user_info)}
"""
    
    # BeszÃ©lgetÃ©si elÅ‘zmÃ©nyek hozzÃ¡adÃ¡sa
    if memory.chat_history:
        recent_history = memory.chat_history[-10:]
        history_text = "\n".join([
            f"{msg.role}: {msg.content[:150]}"
            for msg in recent_history
        ])
        prompt += f"\nKorÃ¡bbi beszÃ©lgetÃ©s:\n{history_text}\n\n"
    
    return prompt
```

#### 1.2 Chain-of-Thought DÃ¶ntÃ©shozatal

Az agent lÃ©pÃ©srÅ‘l lÃ©pÃ©sre gondolkodik Ã©s vÃ¡lasztja ki a megfelelÅ‘ eszkÃ¶zt:

```python
# backend/services/agent.py - _agent_decide_node()

async def _agent_decide_node(self, state: AgentState) -> AgentState:
    """
    LLM dÃ¶ntÃ©si csomÃ³pont - eszkÃ¶z vÃ¡lasztÃ¡s vagy vÃ©gsÅ‘ vÃ¡lasz.
    
    DÃ¶ntÃ©si folyamat:
    1. RAG kontextus ellenÅ‘rzÃ©se (ha van talÃ¡lat â†’ hasznÃ¡ld!)
    2. KorÃ¡bbi eszkÃ¶zhÃ­vÃ¡sok Ã¡ttekintÃ©se (ne ismÃ©tlÅ‘dj!)
    3. ElÃ©rhetÅ‘ eszkÃ¶zÃ¶k listÃ¡ja
    4. Routing dÃ¶ntÃ©s: melyik eszkÃ¶z vagy vÃ©gsÅ‘ vÃ¡lasz?
    """
    
    # System prompt Ã©pÃ­tÃ©se
    system_prompt = self._build_system_prompt(state["memory"])
    
    # RAG kontextus beÃ¡gyazÃ¡sa (LEGMAGASABB PRIORITÃS)
    rag_section = ""
    rag_context = state.get("rag_context", {})
    if rag_context and rag_context.get("has_knowledge", False):
        context_text = rag_context.get("context_text", "")
        citations = rag_context.get("citations", [])
        
        rag_section = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” PRIORITÃS: TUDÃSBÃZIS KERESÃ‰SI EREDMÃ‰NYEK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LekÃ©rt Kontextus:
{context_text}

ElÃ©rhetÅ‘ HivatkozÃ¡sok: {", ".join(citations)}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ KRITIKUS SZABÃLYOK:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. PREFERÃLD A LEKÃ‰RT TUDÃST AZ ESZKÃ–ZÃ–K HELYETT
   - Ha a kontextus vÃ¡laszol a kÃ©rdÃ©sre â†’ hasznÃ¡ld "final_answer"-t rÃ¶gtÃ¶n
   - CSAK akkor hÃ­vj eszkÃ¶zt, ha a tudÃ¡sbÃ¡zis nem elÃ©g

2. KÃ–TELEZÅ HIVATKOZÃS
   - HasznÃ¡ld a formÃ¡tumot: [RAG-1], [RAG-2], stb.
   - SOHA ne Ã¡llÃ­ts olyat, hogy dokumentumbÃ³l van, hivatkozÃ¡s nÃ©lkÃ¼l
"""

    # DÃ¶ntÃ©si prompt - CSAK JSON vÃ¡laszt vÃ¡runk!
    decision_prompt = f"""
Elemezd a felhasznÃ¡lÃ³ kÃ©rÃ©sÃ©t Ã©s vÃ¡laszolj CSAK egy Ã©rvÃ©nyes JSON objektummal.

{rag_section}

ElÃ©rhetÅ‘ eszkÃ¶zÃ¶k:
- weather: IdÅ‘jÃ¡rÃ¡s elÅ‘rejelzÃ©s (paramÃ©terek: city VAGY lat/lon)
- geocode: CÃ­m â†’ koordinÃ¡tÃ¡k vagy fordÃ­tva
- GLOBAL_QUOTE: RÃ©szvÃ©nyÃ¡rak (AlphaVantage MCP)
- CPI: FogyasztÃ³i Ã¡rindex (AlphaVantage MCP)
...

FelhasznÃ¡lÃ³i kÃ©rÃ©s: {last_user_msg}

MÃ¡r meghÃ­vott eszkÃ¶zÃ¶k: {tools_called_info}

KRITIKUS SZABÃLYOK:
1. SOHA ne hÃ­vd meg ugyanazt az eszkÃ¶zt ugyanazokkal a paramÃ©terekkel!
2. Ha egy eszkÃ¶z nem tudta adni az adatot â†’ ne prÃ³bÃ¡ld Ãºjra, menj final_answer-re
3. Csak "final_answer" amikor MINDEN kÃ©rt feladat kÃ©sz VAGY lehetetlen

VÃ¡lasz formÃ¡tum (CSAK JSON, semmi mÃ¡s):
{{
  "action": "call_tool",
  "tool_name": "ESZKÃ–Z_NEVE",
  "arguments": {{...}},
  "reasoning": "rÃ¶vid indoklÃ¡s"
}}

PÃ¡rhuzamos vÃ©grehajtÃ¡shoz (amikor az eszkÃ¶zÃ¶k fÃ¼ggetlenek):
{{
  "action": "call_tools_parallel",
  "tools": [
    {{"tool_name": "GLOBAL_QUOTE", "arguments": {{"symbol": "AAPL"}}}},
    {{"tool_name": "GLOBAL_QUOTE", "arguments": {{"symbol": "TSLA"}}}}
  ],
  "reasoning": "ezek az eszkÃ¶zÃ¶k fÃ¼ggetlenek, futhatnak egyszerre"
}}
"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=decision_prompt)
    ]
    
    # LLM hÃ­vÃ¡s
    response = await self.llm.ainvoke(messages)
    
    # JSON feldolgozÃ¡s
    try:
        content = response.content.strip()
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        
        decision = json.loads(content)
        logger.info(f"Agent dÃ¶ntÃ©s: {decision}")
        
        state["next_action"] = decision.get("action", "final_answer")
        state["tool_decision"] = decision
        
    except json.JSONDecodeError as e:
        logger.error(f"Nem sikerÃ¼lt feldolgozni a dÃ¶ntÃ©st: {e}")
        state["next_action"] = "final_answer"
    
    return state
```

#### 1.3 Routing Logika

A routing mechanizmus irÃ¡nyÃ­tja, hogy melyik node-hoz menjÃ¼nk:

```python
# backend/services/agent.py

def _route_decision(self, state: AgentState) -> str:
    """
    Routing dÃ¶ntÃ©s: melyik node kÃ¶vetkezik?
    
    LehetsÃ©ges utak:
    - "final_answer" â†’ agent_finalize (befejezÃ©s)
    - "call_tool" â†’ tool_xyz (eszkÃ¶z futtatÃ¡s)
    - "call_tools_parallel" â†’ parallel_tool_execution
    - "mcp_tool_execution" â†’ MCP eszkÃ¶z
    """
    next_action = state.get("next_action", "final_answer")
    
    # IterÃ¡ciÃ³s limit ellenÅ‘rzÃ©s (vÃ©gtelen ciklus megelÅ‘zÃ©se)
    iteration_count = state.get("iteration_count", 0)
    if iteration_count >= MAX_ITERATIONS:
        logger.warning(f"Maximum iterÃ¡ciÃ³ ({MAX_ITERATIONS}) elÃ©rve, befejezÃ©s")
        return "final_answer"
    
    # PÃ¡rhuzamos vÃ©grehajtÃ¡s
    if next_action == "call_tools_parallel":
        return "parallel_tool_execution"
    
    # MCP eszkÃ¶z
    if next_action == "mcp_tool_execution":
        return "mcp_tool_execution"
    
    # BeÃ©pÃ­tett eszkÃ¶z
    if next_action == "call_tool":
        tool_name = state.get("tool_decision", {}).get("tool_name")
        if tool_name in self.tools:
            return f"tool_{tool_name}"
    
    # AlapÃ©rtelmezett: vÃ©gsÅ‘ vÃ¡lasz
    return "final_answer"
```

---

## 2. Operational Layer (Workflow)

### CÃ©lja
A workflow rÃ©teg definiÃ¡lja a node-okat, edge-eket Ã©s az Ã¡llapot (state) kezelÃ©st a LangGraph segÃ­tsÃ©gÃ©vel.

### Kulcs Komponensek

#### 2.1 State DefiniÃ¡lÃ¡s

Az AgentState tÃ¡rolja az Ã¶sszes informÃ¡ciÃ³t a workflow sorÃ¡n:

```python
# backend/services/agent.py

from typing import List, Dict, Any, Annotated, Sequence
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage

class AgentState(TypedDict, total=False):
    """LangGraph agent Ã¡llapot RAG tÃ¡mogatÃ¡ssal Ã©s pÃ¡rhuzamos vÃ©grehajtÃ¡ssal."""
    
    # Ãœzenetek Ã©s memÃ³ria
    messages: Sequence[BaseMessage]
    memory: Memory
    current_user_id: str
    
    # EszkÃ¶z vÃ©grehajtÃ¡s
    tools_called: List[ToolCall]
    tool_decision: Dict[str, Any]
    next_action: str
    iteration_count: int  # VÃ©gtelen ciklus elleni vÃ©delem
    
    # RAG mezÅ‘k
    rag_context: Dict[str, Any]  # LekÃ©rt kontextus dokumentumokbÃ³l
    rag_metrics: Dict[str, Any]  # RAG teljesÃ­tmÃ©ny metrikÃ¡k
    skip_rag: bool  # RAG kihagyÃ¡sa (pl. "reset context")
    
    # MCP eszkÃ¶zÃ¶k
    deepwiki_tools: List[Dict[str, Any]]
    alphavantage_tools: List[Dict[str, Any]]
    debug_logs: List[str]  # Debug informÃ¡ciÃ³k frontendnek
    
    # PÃ¡rhuzamos vÃ©grehajtÃ¡s
    parallel_tasks: Annotated[List[Dict[str, Any]], parallel_results_reducer]
    parallel_results: Annotated[List[Dict[str, Any]], parallel_results_reducer]
```

#### 2.2 Graph Ã‰pÃ­tÃ©se (Node-ok Ã©s Edge-ek)

A LangGraph workflow struktÃºra:

```python
# backend/services/agent.py

def _build_graph(self) -> StateGraph:
    """
    LangGraph workflow Ã©pÃ­tÃ©se RAG integrÃ¡ciÃ³val.
    
    Node-ok:
    - rag_pipeline: RAG subgraph (ELSÅ lÃ©pÃ©s)
    - fetch_alphavantage_tools: MCP eszkÃ¶zÃ¶k fetchelÃ©se
    - fetch_deepwiki_tools: MCP eszkÃ¶zÃ¶k fetchelÃ©se
    - agent_decide: LLM dÃ¶ntÃ©shozatal (ciklusban futhat!)
    - tool_*: Egyedi eszkÃ¶z node-ok
    - parallel_tool_execution: PÃ¡rhuzamos eszkÃ¶zÃ¶k
    - agent_finalize: VÃ©gsÅ‘ vÃ¡lasz generÃ¡lÃ¡s
    
    Flow: 
    RAG â†’ fetch_tools â†’ agent_decide â†’ tool â†’ agent_decide (loop) â†’ finalize
    """
    workflow = StateGraph(AgentState)
    
    # NODE-OK HOZZÃADÃSA
    # 1. RAG pipeline (ha konfigurÃ¡lva van)
    if self.rag_subgraph is not None:
        workflow.add_node("rag_pipeline", self.rag_subgraph)
        logger.info("RAG pipeline integrÃ¡lva az agent graph-ba")
    
    # 2. MCP eszkÃ¶z fetchelÃ©s node-ok
    workflow.add_node("fetch_alphavantage_tools", self._fetch_alphavantage_tools_node)
    workflow.add_node("fetch_deepwiki_tools", self._fetch_deepwiki_tools_node)
    
    # 3. Agent dÃ¶ntÃ©si node-ok
    workflow.add_node("agent_decide", self._agent_decide_node)
    workflow.add_node("agent_finalize", self._agent_finalize_node)
    
    # 4. EszkÃ¶z vÃ©grehajtÃ¡s node-ok
    workflow.add_node("mcp_tool_execution", self._mcp_tool_execution_node)
    workflow.add_node("parallel_tool_execution", self._parallel_tool_execution_node)
    
    # 5. BeÃ©pÃ­tett eszkÃ¶zÃ¶k node-jai
    for tool_name in self.tools.keys():
        workflow.add_node(f"tool_{tool_name}", self._create_tool_node(tool_name))
    
    # EDGE-EK DEFINIÃLÃSA
    # BelÃ©pÃ©si pont beÃ¡llÃ­tÃ¡sa
    if self.rag_subgraph is not None:
        workflow.set_entry_point("rag_pipeline")
        workflow.add_edge("rag_pipeline", "fetch_alphavantage_tools")
    else:
        workflow.set_entry_point("fetch_alphavantage_tools")
    
    # LineÃ¡ris edge-ek (mindig ezekben a sorrendben)
    workflow.add_edge("fetch_alphavantage_tools", "fetch_deepwiki_tools")
    workflow.add_edge("fetch_deepwiki_tools", "agent_decide")
    
    # CONDITIONAL EDGES (routing a dÃ¶ntÃ©s alapjÃ¡n)
    workflow.add_conditional_edges(
        "agent_decide",
        self._route_decision,  # Routing fÃ¼ggvÃ©ny
        {
            "final_answer": "agent_finalize",
            "mcp_tool_execution": "mcp_tool_execution",
            "parallel_tool_execution": "parallel_tool_execution",
            **{f"tool_{name}": f"tool_{name}" for name in self.tools.keys()}
        }
    )
    
    # VisszatÃ©rÅ‘ edge-ek (multi-step reasoning)
    for tool_name in self.tools.keys():
        workflow.add_edge(f"tool_{tool_name}", "agent_decide")
    
    workflow.add_edge("mcp_tool_execution", "agent_decide")
    workflow.add_edge("parallel_tool_execution", "agent_decide")
    
    # VÃ©gpont
    workflow.add_edge("agent_finalize", END)
    
    # Compile
    return workflow.compile()
```

#### 2.3 Workflow VizualizÃ¡ciÃ³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LANGGRAPH WORKFLOW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  START                                                          â”‚
â”‚    â”‚                                                            â”‚
â”‚    â–¼                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚  â”‚ rag_pipeline â”‚  â† RAG subgraph (dokumentum keresÃ©s)         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚ fetch_alphavantage_tools â”‚  â† MCP eszkÃ¶zÃ¶k fetchelÃ©se       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚             â”‚                                                   â”‚
â”‚             â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ fetch_deepwiki_toolsâ”‚  â† MCP eszkÃ¶zÃ¶k fetchelÃ©se            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚             â”‚                                                   â”‚
â”‚             â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚  â”‚  agent_decide    â”‚  â† LLM dÃ¶ntÃ©shozatal                     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€â†’ "final_answer" â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚       â”‚                        â”‚ agent_finalize  â”‚ â†’ END       â”‚
â”‚       â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€â†’ "call_tool" â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       â”‚                     â”‚ tool_xyz â”‚ â”€â”€â”                   â”‚
â”‚       â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                   â”‚
â”‚       â”‚                                     â”‚                   â”‚
â”‚       â”œâ”€â”€â†’ "call_tools_parallel" â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚       â”‚                              â”‚ parallel_execute â”‚ â”€â”   â”‚
â”‚       â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚       â”‚                                                    â”‚   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚                                                   â”‚        â”‚   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚              â”‚  â† LOOP: Multi-step reasoning              â”‚   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Tool Execution Layer (KÃ¼lsÅ‘ API-k)

### CÃ©lja
KÃ¼lsÅ‘ API-k meghÃ­vÃ¡sa: adatlekÃ©rÃ©s, Ã­rÃ¡s, szÃ¡mÃ­tÃ¡s. MCP (Model Context Protocol) Ã©s beÃ©pÃ­tett eszkÃ¶zÃ¶k.

### Kulcs Komponensek

#### 3.1 BeÃ©pÃ­tett EszkÃ¶zÃ¶k

```python
# backend/services/tools.py

class WeatherTool:
    """IdÅ‘jÃ¡rÃ¡s eszkÃ¶z - Open-Meteo API."""
    
    async def execute(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        IdÅ‘jÃ¡rÃ¡s lekÃ©rÃ©s paramÃ©terek alapjÃ¡n.
        
        Args:
            arguments: {
                "city": "Budapest" VAGY
                "lat": 47.4979, "lon": 19.0402
            }
        """
        # Geocoding ha szÃ¼ksÃ©ges
        if "city" in arguments:
            geocode_result = await self._geocode(arguments["city"])
            lat, lon = geocode_result["lat"], geocode_result["lon"]
        else:
            lat, lon = arguments["lat"], arguments["lon"]
        
        # Open-Meteo API hÃ­vÃ¡s
        url = "https://api.open-meteo.com/v1/forecast"
        params = {
            "latitude": lat,
            "longitude": lon,
            "current": "temperature_2m,weathercode",
            "daily": "temperature_2m_max,temperature_2m_min,precipitation_sum",
            "timezone": "auto"
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.get(url, params=params)
            response.raise_for_status()
            return response.json()
```

#### 3.2 MCP EszkÃ¶zÃ¶k (AlphaVantage)

Az MCP protokoll lehetÅ‘vÃ© teszi dinamikus eszkÃ¶z felfedezÃ©st:

```python
# backend/services/agent.py - _fetch_alphavantage_tools_node()

async def _fetch_alphavantage_tools_node(self, state: AgentState) -> AgentState:
    """
    AlphaVantage MCP szerver kapcsolat inicializÃ¡lÃ¡sa.
    
    LÃ©pÃ©sek:
    1. KapcsolÃ³dÃ¡s az MCP szerverhez (initialize)
    2. Session ID fogadÃ¡sa
    3. EszkÃ¶zÃ¶k listÃ¡zÃ¡sa (tools/list)
    4. 118 pÃ©nzÃ¼gyi eszkÃ¶z tÃ¡rolÃ¡sa state-ben
    """
    logger.info("AlphaVantage MCP eszkÃ¶zÃ¶k fetchelÃ©se")
    
    alphavantage_tools = []
    
    try:
        # KapcsolÃ³dÃ¡s ellenÅ‘rzÃ©se
        if not hasattr(self.alphavantage_mcp_client, 'connected') or not self.alphavantage_mcp_client.connected:
            import os
            api_key = os.getenv('ALPHAVANTAGE_API_KEY', '')
            logger.info("KapcsolÃ³dÃ¡s AlphaVantage MCP szerverhez")
            
            await self.alphavantage_mcp_client.connect(
                f"https://mcp.alphavantage.co/mcp?apikey={api_key}"
            )
        
        # EszkÃ¶zÃ¶k listÃ¡zÃ¡sa
        alphavantage_tools = await self.alphavantage_mcp_client.list_tools()
        
        logger.info(f"Sikeresen fetchelve {len(alphavantage_tools)} AlphaVantage eszkÃ¶z")
        logger.info(f"ElÃ©rhetÅ‘ eszkÃ¶zÃ¶k: {[t.get('name') for t in alphavantage_tools[:10]]}")
        
    except Exception as e:
        logger.error(f"Hiba AlphaVantage eszkÃ¶zÃ¶k fetchelÃ©se sorÃ¡n: {e}")
        alphavantage_tools = []
    
    # TÃ¡rolÃ¡s state-ben
    state["alphavantage_tools"] = alphavantage_tools
    
    return state
```

#### 3.3 MCP EszkÃ¶z VÃ©grehajtÃ¡s

```python
# backend/services/agent.py - _mcp_tool_execution_node()

async def _mcp_tool_execution_node(self, state: AgentState) -> AgentState:
    """
    MCP eszkÃ¶z meghÃ­vÃ¡sa (DeepWiki vagy AlphaVantage).
    
    JSON-RPC 2.0 protokoll hasznÃ¡lata:
    POST /mcp
    {
        "jsonrpc": "2.0",
        "method": "tools/call",
        "params": {
            "name": "GLOBAL_QUOTE",
            "arguments": {"symbol": "AAPL"}
        }
    }
    """
    tool_decision = state.get("tool_decision", {})
    tool_name = tool_decision.get("tool_name")
    arguments = tool_decision.get("arguments", {})
    
    logger.info(f"MCP eszkÃ¶z vÃ©grehajtÃ¡sa: {tool_name} args={arguments}")
    
    try:
        # EszkÃ¶z meghÃ­vÃ¡sa
        result = await self.alphavantage_mcp_client.call_tool(
            name=tool_name,
            arguments=arguments
        )
        
        # EredmÃ©ny tÃ¡rolÃ¡sa
        tool_call = ToolCall(
            tool_name=tool_name,
            arguments=arguments,
            result=result,
            timestamp=datetime.now()
        )
        
        state["tools_called"].append(tool_call)
        
        # System message hozzÃ¡adÃ¡sa az eredmÃ©nnyel
        result_summary = json.dumps(result)[:500]  # ElsÅ‘ 500 karakter
        system_msg = f"EszkÃ¶z '{tool_name}' eredmÃ©nye:\n{result_summary}"
        state["messages"].append(SystemMessage(content=system_msg))
        
    except Exception as e:
        logger.error(f"MCP eszkÃ¶z hiba: {e}")
        error_msg = f"Hiba '{tool_name}' eszkÃ¶z futtatÃ¡sa sorÃ¡n: {str(e)}"
        state["messages"].append(SystemMessage(content=error_msg))
    
    return state
```

#### 3.4 PÃ¡rhuzamos EszkÃ¶z VÃ©grehajtÃ¡s

A fÃ¼ggetlen eszkÃ¶zÃ¶k egyidejÅ± futtatÃ¡sa jelentÅ‘s teljesÃ­tmÃ©nynÃ¶vekedÃ©st eredmÃ©nyez:

```python
# backend/services/parallel_execution.py

async def execute_parallel_mcp_tools(
    tasks: List[Dict],
    alphavantage_client,
    session_id: str
) -> List[Dict]:
    """
    TÃ¶bb MCP eszkÃ¶z pÃ¡rhuzamos futtatÃ¡sa asyncio.gather-rel.
    
    PÃ©lda:
    tasks = [
        {"tool_name": "GLOBAL_QUOTE", "arguments": {"symbol": "AAPL"}},
        {"tool_name": "GLOBAL_QUOTE", "arguments": {"symbol": "TSLA"}}
    ]
    
    EredmÃ©ny: 2 eszkÃ¶z ~3 mp alatt (szekvenciÃ¡lis: ~6 mp)
    """
    
    async def execute_single_tool(task: Dict) -> Dict:
        try:
            result = await alphavantage_client.call_tool(
                name=task["tool_name"],
                arguments=task["arguments"],
                session_id=session_id
            )
            return {
                "tool_name": task["tool_name"],
                "arguments": task["arguments"],
                "result": result,
                "success": True
            }
        except Exception as e:
            return {
                "tool_name": task["tool_name"],
                "arguments": task["arguments"],
                "error": str(e),
                "success": False
            }
    
    # PÃ¡rhuzamos futtatÃ¡s - asyncio.gather!
    logger.info(f"PÃ¡rhuzamos futtatÃ¡s: {len(tasks)} MCP eszkÃ¶z")
    
    results = await asyncio.gather(*[
        execute_single_tool(task) for task in tasks
    ])
    
    successful = sum(1 for r in results if r["success"])
    failed = sum(1 for r in results if not r["success"])
    
    logger.info(f"PÃ¡rhuzamos vÃ©grehajtÃ¡s kÃ©sz: {successful} sikeres, {failed} sikertelen")
    
    return results
```

**TeljesÃ­tmÃ©ny Ã¶sszehasonlÃ­tÃ¡s:**
```
SzekvenciÃ¡lis:
  Tool 1: 3 mp
  Tool 2: 3 mp
  Total: 6 mp

PÃ¡rhuzamos (asyncio.gather):
  Tool 1 + Tool 2 egyidejÅ±leg: ~3 mp
  Speedup: 2x
```

---

## 4. Memory / RAG / Context Handling

### CÃ©lja
Stateful mÅ±kÃ¶dÃ©s biztosÃ­tÃ¡sa: beszÃ©lgetÃ©si elÅ‘zmÃ©nyek, felhasznÃ¡lÃ³i preferenciÃ¡k, dokumentum-alapÃº kontextus (RAG), retrieval-before-tools stratÃ©gia.

### Kulcs Komponensek

#### 4.1 Memory StruktÃºra

```python
# backend/domain/models.py

from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
from datetime import datetime

class Message(BaseModel):
    """Egyetlen Ã¼zenet a beszÃ©lgetÃ©sben."""
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)

class WorkflowState(BaseModel):
    """Workflow Ã¡llapot kÃ¶vetÃ©se."""
    flow: str = ""  # "onboarding", "weather_check", stb.
    step: int = 0
    total_steps: int = 0
    data: Dict[str, Any] = Field(default_factory=dict)

class Memory(BaseModel):
    """
    FelhasznÃ¡lÃ³i memÃ³ria - perzisztens Ã¡llapot.
    
    Tartalmazza:
    - chat_history: BeszÃ©lgetÃ©si elÅ‘zmÃ©nyek
    - preferences: FelhasznÃ¡lÃ³i beÃ¡llÃ­tÃ¡sok (vÃ¡ros, nyelv, stb.)
    - workflow_state: AktÃ­v workflow Ã¡llapot
    """
    chat_history: List[Message] = Field(default_factory=list)
    preferences: Dict[str, Any] = Field(default_factory=dict)
    workflow_state: WorkflowState = Field(default_factory=WorkflowState)
```

#### 4.2 RAG Pipeline (Retrieval-Before-Tools)

A RAG pipeline **MINDEN kÃ©rÃ©s ELÅTT** fut, dokumentum alapÃº kontextust biztosÃ­tva:

```python
# backend/rag/rag_graph.py

from langgraph.graph import StateGraph, END

class RAGState(TypedDict):
    """RAG pipeline Ã¡llapot."""
    messages: Sequence[BaseMessage]
    user_id: str
    
    # RAG feldolgozÃ¡s mezÅ‘k
    original_query: str
    rewritten_query: str  # OptimalizÃ¡lt keresÃ©si query
    retrieved_chunks: List[Dict[str, Any]]  # LekÃ©rt dokumentum darabok
    context_text: str  # Ã–sszefÅ±zÃ¶tt kontextus
    citations: List[str]  # HivatkozÃ¡sok
    has_knowledge: bool  # Van-e relevÃ¡ns tudÃ¡s?

def build_rag_graph() -> StateGraph:
    """
    RAG subgraph Ã©pÃ­tÃ©se.
    
    Pipeline:
    1. query_rewrite: Query optimalizÃ¡lÃ¡s (kÃ©rdÃ©s â†’ kulcsszavak)
    2. retrieve: Dokumentum keresÃ©s vektoradatbÃ¡zisban
    3. format_context: Kontextus formÃ¡zÃ¡sa LLM-nek
    """
    workflow = StateGraph(RAGState)
    
    workflow.add_node("query_rewrite", query_rewrite_node)
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("format_context", format_context_node)
    
    workflow.set_entry_point("query_rewrite")
    workflow.add_edge("query_rewrite", "retrieve")
    workflow.add_edge("retrieve", "format_context")
    workflow.add_edge("format_context", END)
    
    return workflow.compile()
```

#### 4.3 Query Rewriting

Az eredeti kÃ©rdÃ©s optimalizÃ¡lÃ¡sa keresÃ©shez:

```python
# backend/rag/rag_nodes.py

async def query_rewrite_node(state: RAGState) -> RAGState:
    """
    Query ÃºjraÃ­rÃ¡s - beszÃ©lgetÃ©si kÃ©rdÃ©s â†’ keresÃ©si kulcsszavak.
    
    PÃ©lda:
    User: "Ã‰s mennyi a bevÃ©tele?"
    Chat history: "KÃ©rdeztem az Apple-rÅ‘l..."
    
    Rewritten: "Apple bevÃ©tel revenue earnings"
    """
    original_query = state["original_query"]
    
    # Chat history kontextus
    recent_history = state["messages"][-5:] if state["messages"] else []
    history_text = "\n".join([f"{msg.type}: {msg.content}" for msg in recent_history])
    
    prompt = f"""
AlakÃ­tsd Ã¡t a felhasznÃ¡lÃ³i kÃ©rdÃ©st optimÃ¡lis keresÃ©si query-vÃ©.

BeszÃ©lgetÃ©si kontextus:
{history_text}

AktuÃ¡lis kÃ©rdÃ©s: {original_query}

Add vissza CSAK a keresÃ©si kulcsszavakat, semmi mÃ¡st!
"""
    
    llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0)
    response = await llm.ainvoke([HumanMessage(content=prompt)])
    
    state["rewritten_query"] = response.content.strip()
    logger.info(f"Query rewrite: '{original_query}' â†’ '{state['rewritten_query']}'")
    
    return state
```

#### 4.4 Vector Store KeresÃ©s

```python
# backend/rag/retrieval_service.py

from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

class RetrievalService:
    """Dokumentum keresÃ©si szolgÃ¡ltatÃ¡s."""
    
    def __init__(self, vector_store_path: str, openai_api_key: str):
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.vector_store = Chroma(
            persist_directory=vector_store_path,
            embedding_function=self.embeddings
        )
    
    async def retrieve(
        self,
        query: str,
        user_id: str,
        top_k: int = 3
    ) -> List[Dict[str, Any]]:
        """
        Dokumentum keresÃ©s vektoradatbÃ¡zisban.
        
        Args:
            query: KeresÃ©si query (mÃ¡r ÃºjraÃ­rt!)
            user_id: FelhasznÃ¡lÃ³ azonosÃ­tÃ³ (szÅ±rÃ©shez)
            top_k: HÃ¡ny dokumentumot kÃ©rjÃ¼nk le
        
        Returns:
            Lista dokumentum chunk-okrÃ³l metaadatokkal
        """
        # SzÅ±rÅ‘: csak az adott user dokumentumai
        filter_dict = {"user_id": user_id}
        
        # Similarity search
        results = self.vector_store.similarity_search_with_score(
            query=query,
            k=top_k,
            filter=filter_dict
        )
        
        chunks = []
        for doc, score in results:
            chunks.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity_score": score,
                "citation": f"{doc.metadata.get('filename', 'Unknown')} - {doc.metadata.get('chunk_id', '')}"
            })
        
        logger.info(f"LekÃ©rve {len(chunks)} chunk query-hez: '{query}'")
        
        return chunks
```

#### 4.5 Context FormÃ¡zÃ¡s

```python
# backend/rag/rag_nodes.py

async def format_context_node(state: RAGState) -> RAGState:
    """
    LekÃ©rt chunk-ok formÃ¡zÃ¡sa LLM-nek.
    
    Output: StrukturÃ¡lt kontextus hivatkozÃ¡sokkal.
    """
    chunks = state.get("retrieved_chunks", [])
    
    if not chunks:
        state["has_knowledge"] = False
        state["context_text"] = ""
        state["citations"] = []
        return state
    
    # Chunk-ok Ã¶sszefÅ±zÃ©se
    context_parts = []
    citations = []
    
    for idx, chunk in enumerate(chunks, start=1):
        citation_id = f"RAG-{idx}"
        content = chunk["content"]
        citation_text = chunk["citation"]
        
        context_parts.append(f"[{citation_id}] {content}")
        citations.append(f"{citation_id}: {citation_text}")
    
    state["context_text"] = "\n\n".join(context_parts)
    state["citations"] = citations
    state["has_knowledge"] = True
    
    logger.info(f"Kontextus formÃ¡zva: {len(chunks)} chunk, {len(citations)} hivatkozÃ¡s")
    
    return state
```

#### 4.6 Retrieval-Before-Tools StratÃ©gia

A RAG pipeline **mindig elÅ‘szÃ¶r** fut, az eszkÃ¶zÃ¶k elÅ‘tt:

```python
# backend/services/agent.py - _build_graph()

# Graph Ã©pÃ­tÃ©s sorrend:
if self.rag_subgraph is not None:
    workflow.set_entry_point("rag_pipeline")  # â† ELSÅ LÃ‰PÃ‰S!
    workflow.add_edge("rag_pipeline", "fetch_alphavantage_tools")
else:
    workflow.set_entry_point("fetch_alphavantage_tools")

# Flow:
# 1. RAG pipeline (dokumentum keresÃ©s)
# 2. MCP tools fetch (eszkÃ¶z felfedezÃ©s)
# 3. Agent decide (dÃ¶ntÃ©s: hasznÃ¡ld a dokumentumot VAGY hÃ­vj eszkÃ¶zt)
```

**PrioritÃ¡si sorrend az LLM dÃ¶ntÃ©shozatalban:**

```
1. LEGMAGASABB PRIORITÃS: RAG kontextus
   â””â”€> Ha van talÃ¡lat â†’ hasznÃ¡ld Ã©s hivatkozz rÃ¡!
   â””â”€> Csak akkor hÃ­vj eszkÃ¶zt, ha a dokumentum NEM elÃ©g

2. KÃ–ZEPES PRIORITÃS: EszkÃ¶zhÃ­vÃ¡s kontextussal
   â””â”€> Chat history Ã©s preferenciÃ¡k beÃ¡gyazÃ¡sa az argumentumokba

3. LEGALACSONYABB PRIORITÃS: Direkt eszkÃ¶zhÃ­vÃ¡s
   â””â”€> Explicit paramÃ©terek a felhasznÃ¡lÃ³i Ã¼zenetbÅ‘l
```

---

## Ã–sszefoglalÃ¡s: 4 RÃ©teg EgyÃ¼ttmÅ±kÃ¶dÃ©se

### Teljes Folyamat PÃ©lda

**FelhasznÃ¡lÃ³i kÃ©rdÃ©s:** "Get stock prices for AAPL and TSLA"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. REASONING LAYER (LLM)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ System Prompt: "Te egy AI asszisztens vagy..."                 â”‚
â”‚ Chain-of-Thought:                                               â”‚
â”‚   - RAG kontextus: Nincs relevÃ¡ns dokumentum                    â”‚
â”‚   - ElÃ©rhetÅ‘ eszkÃ¶zÃ¶k: GLOBAL_QUOTE (AlphaVantage MCP)         â”‚
â”‚   - DÃ¶ntÃ©s: 2 fÃ¼ggetlen eszkÃ¶z â†’ pÃ¡rhuzamos futtatÃ¡s!          â”‚
â”‚                                                                 â”‚
â”‚ Output JSON:                                                    â”‚
â”‚ {                                                               â”‚
â”‚   "action": "call_tools_parallel",                             â”‚
â”‚   "tools": [                                                    â”‚
â”‚     {"tool_name": "GLOBAL_QUOTE", "arguments": {"symbol": "AAPL"}},â”‚
â”‚     {"tool_name": "GLOBAL_QUOTE", "arguments": {"symbol": "TSLA"}} â”‚
â”‚   ]                                                             â”‚
â”‚ }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. OPERATIONAL LAYER (Workflow)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ StateGraph routing:                                             â”‚
â”‚   agent_decide â†’ _route_decision()                              â”‚
â”‚   â†’ next_action = "call_tools_parallel"                         â”‚
â”‚   â†’ Route to: "parallel_tool_execution" node                    â”‚
â”‚                                                                 â”‚
â”‚ State update:                                                   â”‚
â”‚   state["parallel_tasks"] = [AAPL task, TSLA task]             â”‚
â”‚   state["iteration_count"] += 1                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TOOL EXECUTION LAYER (KÃ¼lsÅ‘ API-k)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PÃ¡rhuzamos vÃ©grehajtÃ¡s (asyncio.gather):                        â”‚
â”‚                                                                 â”‚
â”‚   Task 1: MCP call_tool(GLOBAL_QUOTE, AAPL)                    â”‚
â”‚   â”œâ”€ POST https://mcp.alphavantage.co/mcp                      â”‚
â”‚   â”œâ”€ JSON-RPC: tools/call                                       â”‚
â”‚   â””â”€ Result: {"symbol": "AAPL", "price": "225.33", ...}        â”‚
â”‚                                                                 â”‚
â”‚   Task 2: MCP call_tool(GLOBAL_QUOTE, TSLA)                    â”‚
â”‚   â”œâ”€ POST https://mcp.alphavantage.co/mcp                      â”‚
â”‚   â”œâ”€ JSON-RPC: tools/call                                       â”‚
â”‚   â””â”€ Result: {"symbol": "TSLA", "price": "242.84", ...}        â”‚
â”‚                                                                 â”‚
â”‚ Total time: ~3 mÃ¡sodperc (szekvenciÃ¡lis: ~6 mp)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MEMORY / CONTEXT HANDLING                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ State update (stateful mÅ±kÃ¶dÃ©s):                                â”‚
â”‚                                                                 â”‚
â”‚ state["tools_called"].append(                                   â”‚
â”‚   ToolCall(                                                     â”‚
â”‚     tool_name="GLOBAL_QUOTE",                                   â”‚
â”‚     arguments={"symbol": "AAPL"},                               â”‚
â”‚     result={...},                                               â”‚
â”‚     timestamp=datetime.now()                                    â”‚
â”‚   )                                                             â”‚
â”‚ )                                                               â”‚
â”‚                                                                 â”‚
â”‚ memory.chat_history.append(                                     â”‚
â”‚   Message(                                                      â”‚
â”‚     role="system",                                              â”‚
â”‚     content="Tool results: AAPL=$225.33, TSLA=$242.84"          â”‚
â”‚   )                                                             â”‚
â”‚ )                                                               â”‚
â”‚                                                                 â”‚
â”‚ KÃ¶vetkezÅ‘ iterÃ¡ciÃ³nÃ¡l:                                          â”‚
â”‚   - LLM lÃ¡tja a korÃ¡bbi tool call-t                             â”‚
â”‚   - NEM ismÃ©tli meg ugyanazt                                    â”‚
â”‚   - Ã–sszegzi az eredmÃ©nyt                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                      LOOP BACK TO:
                    agent_decide node
                            â†“
                  DÃ¶ntÃ©s: "final_answer"
                            â†“
                  agent_finalize node
                            â†“
         VÃ©gsÅ‘ vÃ¡lasz: "AAPL: $225.33, TSLA: $242.84"
```

---

## Kulcs TanulsÃ¡gok

### 1. Reasoning Layer
- **System Prompt**: SzemÃ©lyisÃ©g + kontextus + szabÃ¡lyok
- **Chain-of-Thought**: LÃ©pÃ©srÅ‘l lÃ©pÃ©sre gondolkodÃ¡s
- **JSON Output**: StrukturÃ¡lt dÃ¶ntÃ©shozatal
- **Routing**: Intelligens node kivÃ¡lasztÃ¡s

### 2. Operational Layer
- **StateGraph**: LangGraph workflow definiÃ¡lÃ¡s
- **Node-ok**: FunkcionÃ¡lis egysÃ©gek (RAG, eszkÃ¶z, dÃ¶ntÃ©s)
- **Edge-ek**: Workflow irÃ¡nyÃ­tÃ¡s (lineÃ¡ris + conditional)
- **State**: InformÃ¡ciÃ³ perzisztencia node-ok kÃ¶zÃ¶tt

### 3. Tool Execution Layer
- **BeÃ©pÃ­tett EszkÃ¶zÃ¶k**: Python kÃ³d vÃ©grehajtÃ¡s
- **MCP EszkÃ¶zÃ¶k**: Dinamikus felfedezÃ©s + JSON-RPC hÃ­vÃ¡s
- **PÃ¡rhuzamos FuttatÃ¡s**: asyncio.gather teljesÃ­tmÃ©nynÃ¶vekedÃ©shez
- **HibakezelÃ©s**: Try-except minden eszkÃ¶znÃ©l

### 4. Memory / RAG / Context
- **Retrieval-Before-Tools**: Dokumentumok ELÅSZÃ–R
- **Vector Store**: Szemantikus keresÃ©s
- **Query Rewriting**: BeszÃ©lgetÃ©s â†’ kulcsszavak
- **Citations**: KÃ¶telezÅ‘ hivatkozÃ¡s dokumentumokra
- **Stateful Memory**: Chat history + preferences perzisztencia

---

**VerziÃ³:** 1.0 (2026-01-13)  
**SzerzÅ‘:** AI Agent Development Team  
**Alapul:** Claude Sonnet 4 + LangGraph + MCP Protocol
