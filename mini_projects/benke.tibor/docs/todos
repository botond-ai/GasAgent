## ‚úÖ Elk√©sz√ºlt Fejleszt√©sek

- [x] Max bemeneti token limit be√©p√≠t√©s (10k tokens, HTTP 413)
- [x] Hibakezel√©s be√©p√≠t√©s (retry logic, exponential backoff, detailed status codes)
- [x] Multi-domain Qdrant collection (domain filtering, payload index)
- [x] Centraliz√°lt OpenAI kliensek (singleton pattern, error handling)
- [x] Token tracking √©s k√∂lts√©g kalkul√°ci√≥ (/api/usage-stats/)
- [x] Input valid√°ci√≥ (empty check, token limit)
- [x] Prompt truncation (100k token limit, auto-truncate)
- [x] Frontend cleanup (debug panel, markdown formatting, refresh button)
- [x] Swagger API dokument√°ci√≥ (docs/API.md)
- [x] README friss√≠t√©s (hibakezel√©s, production features, API endpoints)
- [x] Unit tesztek (61 teszt, 87-100% coverage tested modules)
- [x] Redis cache (embedding + query result, /api/cache-stats/)
- [x] Cache invalid√°l√°s (sync_domain_docs.py auto-invalidation)
- [x] Dokument√°ci√≥ friss√≠t√©s (README, INSTALLATION, API.md, REDIS_CACHE.md)
- [x] **Like/Dislike feedback backend**: PostgreSQL + async client + API endpoints
- [x] **Feedback system**: POST /api/feedback/citation/, GET /api/feedback/stats/
- [x] **Domain-scoped aggregation**: Materialized views, background threading
- [x] **Uvicorn ASGI migration**: Async view support, Postgres connection pooling
- [x] **Feedback unit tests**: test_feedback_system.py, test_redis_cache.py
- [x] **API.md update**: Version 2.1, feedback endpoints documented

## üöß J√∂v≈ëbeli Fejleszt√©sek

### High Priority
- [ ] **Frontend feedback UI**: üëçüëé gombok citation-√∂k√∂n (m√°r k√©sz a k√≥d, csak tesztelni kell √©les k√∂rnyezetben)
- [ ] **Citation display fix**: Forr√°sok megjelen√≠t√©se vissza√°ll√≠t√°s (elt≈±nt a UI-r√≥l)
- [ ] **Rerank**: Citation re-ranking feedback-weighted semantic relevancia alapj√°n
- [ ] **Chain of link**: Tal√°lati relevancia m√©r√©sek √©s tracking
- [ ] **Multi-query**: Query generation (5 vari√°ci√≥), frequency-based ranking
- [ ] **Integration tesztek**: Multi-domain RAG + feedback end-to-end

### Medium Priority
- [ ] **Query embedding context scoring**: Feedback aggregation embedding similarity-vel
- [ ] **Frontend citation re-ranking**: Live feedback-based result reordering
- [ ] **Szenzit√≠v adatok kisz≈±r√©se**: PII detection a promptb√≥l (email, phone, SSN)
- [ ] **Rate limiting**: Per-user rate limits (100 req/hour)
- [ ] **Monitoring dashboard**: Prometheus + Grafana metrics (cache hit rate, feedback stats)
- [ ] **BM25 sparse vectors**: Lexik√°lis keres√©s t√°mogat√°s (m√°rkanevek, k√≥dok)

### Low Priority
- [ ] **Authentication**: API key vagy JWT token auth
- [ ] **Audit logging**: Compliance log minden query-hez
- [ ] **Cost alerting**: Email alert napi/havi k√∂lts√©g k√ºsz√∂b t√∫ll√©p√©s√©n√©l
- [ ] **WebSocket support**: Real-time streaming responses
- [ ] **Multi-language support**: Automatikus nyelvdetekci√≥ √©s ford√≠t√°s
- [ ] **Feedback analytics dashboard**: Admin UI feedback trends-hez

## üéØ Hf (4) - Multi-Tool Agent Fejleszt√©s

### R√©tegek szerint csoportos√≠tva (Architecture Analysis alapj√°n)

#### **F√°zis 1: Reasoning Layer B≈ëv√≠t√©s (1-2 h√©t)**

##### 1.1 Plan Node
- [ ] ExecutionPlan Pydantic model (steps, tools, data_sources)
- [ ] Plan node implement√°ci√≥ (_plan_node)
- [ ] LLM prompt: "Think step-by-step to answer this query"
- [ ] Graph edge: intent_detection ‚Üí plan_node ‚Üí retrieval

##### 1.2 Chain-of-Thought Explicit Prompting
- [ ] Update intent_detection prompt CoT-tal
- [ ] Update generation prompt CoT-tal
- [ ] Update plan_node prompt reasoning guidance-dal
- [ ] Test: Verify step-by-step reasoning in LLM responses

##### 1.3 Tool Selection Node (Router Tool)
- [ ] ToolSelection Pydantic model
- [ ] Tool selector node (_tool_selection_node)
- [ ] LLM d√∂nt: RAG? Jira? Email? Calculation?
- [ ] Conditional routing: Tool Selection ‚Üí [RAG | Jira | Custom]

**Deliverable:** AGENT_ARCHITECTURE_ANALYSIS.md alapj√°n
- Dokument√°ci√≥: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_1.md
- K√≥d: Plan + Tool Selection nodes
- Tesztek: test_plan_node.py, test_tool_selection.py

---

#### **F√°zis 2: Tool Execution Layer (2-3 h√©t)**

##### 2.1 Tool Registry & Registry Pattern
- [ ] ToolRegistry klasz (register, get_descriptions, execute)
- [ ] Tool schema extraction (type hints ‚Üí JSON schema)
- [ ] Registry initialization (RAG, Jira, Email, Calculator tools)
- [ ] infrastructure/tool_registry.py

##### 2.2 Tool Executor Loop
- [ ] ToolExecutor node (_tool_executor_loop_node)
- [ ] Iterat√≠v tool execution (plan steps iterate)
- [ ] Error handling per tool (timeout, retry, fallback)
- [ ] Tool results collection & logging

##### 2.3 Observation Node
- [ ] ObservationOutput Pydantic model
- [ ] Observation node (_observation_node)
- [ ] LLM √©rt√©keli: "Do I have enough info?"
- [ ] Conditional routing: Observation ‚Üí [Generate | Replan]

##### 2.4 Planner Fallback (Error Recovery)
- [ ] Retry node planner fallback-kel
- [ ] Tool fail ‚Üí LLM replan trigger
- [ ] Max replans limit (prevent infinite loops)
- [ ] Degradation: Tool unavailable ‚Üí summary-only

**Deliverable:**
- Dokument√°ci√≥: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_2.md
- K√≥d: Tool Registry, Executor, Observation nodes
- Tesztek: test_tool_executor.py, test_observation.py
- Integration test: test_executor_loop.py

---

#### **F√°zis 3: Error Handling & Resilience (1-2 h√©t)**

##### 3.1 Retry Node (id≈ëszakos API hib√°k)
- [ ] RetryNode implement√°ci√≥ (max_retries, exponential backoff)
- [ ] Tool retry wrapper (already have with_timeout_and_retry)
- [ ] Separate retry node for orchestration-level retries
- [ ] Error classification (transient vs permanent)

##### 3.2 Fallback Model (olcs√≥-dr√°ga modell)
- [ ] Fallback model selection logic
- [ ] gpt-4o-mini (default) ‚Üí gpt-3.5-turbo (fallback)
- [ ] Cost optimization: Preferr cheaper model wenn m√∂glijk
- [ ] State tracking: which model was used

##### 3.3 Guardian Node (AI Act Compliance)
- [ ] GuardianNode: Validates outputs gegen policies
- [ ] Sensitive data detection (PII, secrets)
- [ ] Content policy check
- [ ] Audit logging for compliance

##### 3.4 Fail-Safe Response Mechanism
- [ ] FailSafeResponse Pydantic model
- [ ] Ultimate fallback responses (Hungarian + English)
- [ ] Graceful degradation: Tool fail ‚Üí summary-only
- [ ] User notification: Clear error messages

**Deliverable:**
- Dokument√°ci√≥: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_3.md
- K√≥d: Retry, Guardian, FailSafe nodes
- Tesztek: test_retry_node.py, test_guardian.py, test_fail_safe.py

---

#### **F√°zis 4: Memory & Context Handling (1-2 h√©t)**

##### 4.1 Long-Term Memory (Persistent User Profiles)
- [ ] UserProfile DB schema (Postgres)
- [ ] UserMemoryStore class (CRUD operations)
- [ ] Profile loading in intent_detection
- [ ] Facts accumulation across sessions

##### 4.2 Multi-Level Summarization
- [ ] Short tier (8 messages)
- [ ] Medium tier (50 messages)
- [ ] Long tier (200+ messages)
- [ ] Automatic tier selection based on message count

##### 4.3 Retrieval-Before-Tools Enforcement
- [ ] Verify RAG runs before Tool Executor
- [ ] RAG context augmentation in tool prompts
- [ ] Tool observation feeds back to memory

**Deliverable:**
- Dokument√°ci√≥: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_4.md
- K√≥d: UserMemoryStore, Multi-level summarization
- DB Migration: user_profiles table
- Tesztek: test_user_memory.py, test_multi_level_summary.py

---

#### **F√°zis 5: Monitoring & Observability (1-2 h√©t)**

##### 5.1 Prometheus Metrics Integration
- [ ] prometheus_client setup
- [ ] LLM call metrics (count, latency, tokens)
- [ ] Tool execution metrics (success rate, latency per tool)
- [ ] RAG metrics (retrieval latency, hit rate)
- [ ] Workflow metrics (decision paths, retry counts)
- [ ] Cache metrics (hit rate, invalidation count)
- [ ] Error rates & breakdown by type
- [ ] Cost tracking (per model, per user, cumulative)

##### 5.2 Grafana Dashboard
- [ ] Node Performance Dashboard (latencies by node)
- [ ] RAG Performance Dashboard (top queries, hit rates)
- [ ] LLM Cost Dashboard (cost per model, burn rate)
- [ ] Error Dashboard (error types, frequencies, trends)
- [ ] System Health Dashboard (active agents, memory usage)

##### 5.3 Loki Logging Integration
- [ ] Structured logging (JSON format)
- [ ] Log labels (node, domain, user_id, session_id)
- [ ] Log queries for debugging
- [ ] Alert rules (high latency, errors, cost anomalies)

##### 5.4 OpenTelemetry Tracing
- [ ] Trace initialization (tracer provider)
- [ ] Span per node execution
- [ ] Span attributes (input, output, latency, status)
- [ ] Distributed tracing (frontend ‚Üî backend)

##### 5.5 Alerting & Anomaly Detection
- [ ] Prometheus AlertManager rules
- [ ] Timeout alerts (> 30s latency)
- [ ] Cost anomaly alerts (daily burn rate exceeded)
- [ ] Error rate alerts (> 5% error rate)
- [ ] Infinite loop detection (max replans exceeded)

**Deliverable:**
- Dokument√°ci√≥: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_5.md
- K√≥d: Prometheus metrics, Grafana configs, Loki setup
- Docker: prometheus, grafana, loki services (docker-compose)
- Alerts: AlertManager rules, runbooks

---

### üîÑ Routing Decision Patterns (Projekt√ºnkh√∂z alkalmas)

Elemz√©s: Melyik routing pattern alkalmazhat√≥?

- [ ] **State-based Routing** ‚úÖ Aj√°nlott
  - Current domain, tool availability, user profile alapj√°n
  - Implement√°lva: guardrail conditional edge
  - Kiterjeszt√©s: Tool selection ‚Üí [RAG | Jira | Email | Calculator]

- [ ] **Confidence-based Routing** ‚úÖ Aj√°nlott
  - Intent detection confidence ‚Üí If < 0.5 use fallback model
  - Tool executor observation ‚Üí If not sufficient, replan
  - Implement√°lva: Intent detection confidence field
  - Kiterjeszt√©s: Tool selection observation

- [ ] **Input-based Routing** ‚ö†Ô∏è Korl√°tozottan
  - Query keywords ‚Üí domain triage
  - Implement√°lva: Marketing keywords detection
  - Kiterjeszt√©s: Tool selection keywords ("jira", "email", "calculate")

- [ ] **Tool-Availability Routing** ‚úÖ Aj√°nlott
  - Which tools are available/enabled?
  - Fallback ha tool unavailable
  - Implement√°lva: Tool registry pattern
  - Kiterjeszt√©s: Check tool health before routing

---

### üìä Performance Optimization Javaslatok

- [ ] **Prompt Optimization**
  - DELTA prompting (delta between current & previous)
  - Tokens cs√∂kkent√©s (avg 15-20%)
  - Few-shot examples vs Chain-of-Thought tradeoff

- [ ] **Caching Strategy**
  - Plan caching (same query ‚âà same plan?)
  - Tool result caching (24h TTL)
  - Embedding cache (current 7d TTL OK)

- [ ] **Parallelization**
  - Parallel tool execution (non-dependent tools)
  - Parallel RAG + Tool execution (after plan)
  - Async/await optimization

- [ ] **Model Selection**
  - Fast track: Use gpt-3.5-turbo for simple queries
  - Smart fallback: Retry with gpt-4o if 3.5 fails
  - Cost vs accuracy optimization

**Referencia:** https://github.com/adrgul/ai_agent_tutorial/blob/main/docs/DELTA_PROMPT.md

---

### üìà Implementation Roadmap

```
Week 1-2:  F√°zis 1 (Plan + CoT + Tool Selection)
Week 3-4:  F√°zis 2 (Tool Registry + Executor Loop + Observation)
Week 5-6:  F√°zis 3 (Retry + Guardian + FailSafe)
Week 7-8:  F√°zis 4 (Long-term Memory + Multi-level Summary)
Week 9-10: F√°zis 5 (Monitoring + Prometheus + Grafana)
```

**Parallel:** Testing & Documentation (minden f√°zissal)

---

### üìö Dokument√°ci√≥ & Referenci√°k

- Saj√°t: docs/h√°zi feladatok/AGENT_ARCHITECTURE_ANALYSIS.md ‚úÖ
- Saj√°t: docs/h√°zi feladatok/IMPLEMENTATION_PHASE_*.md (todo)
- K√ºls≈ë: https://github.com/adrgul/ai_agent_tutorial/blob/main/docs/AI_AGENT_4_RETEG_ARCHITEKTURA.md
- K√ºls≈ë: https://github.com/adrgul/ai_agent_tutorial/blob/main/docs/09_MONITORING_PROMPT.md

---

### üöÄ Quick Wins (MVPs)

Ha gyorsan akarn√°nk progresszi√≥t:

1. **2-3 nap:** Plan Node alapok (1.1)
2. **3-4 nap:** Tool Selection Node (1.3)
3. **1 h√©t:** Tool Executor Loop (2.2)
4. **3 nap:** Observation Node (2.3)

**Teljes F√°zis 1-2:** ~4-5 h√©t = Core complex agent capabilities

---

### ‚öôÔ∏è M√≥dos√≠tand√≥ F√°jlok (Priorit√°s)

**Backend**
- services/agent.py (√∫j nodes)
- domain/llm_outputs.py (ExecutionPlan, ToolSelection, ObservationOutput)
- domain/models.py (kiterjeszt√©s)
- infrastructure/tool_registry.py (NEW)
- infrastructure/user_memory.py (NEW - F√°zis 4)
- tests/test_plan_node.py (NEW)
- tests/test_tool_executor.py (NEW)

**Frontend** (F√°zis 5)
- Debug panel kiterjeszt√©s (monitoring info)

**DevOps** (F√°zis 5)
- docker-compose.yml (prometheus, grafana, loki)
- docs/MONITORING.md (NEW)