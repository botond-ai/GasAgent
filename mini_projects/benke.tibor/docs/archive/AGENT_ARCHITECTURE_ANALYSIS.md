# √ñsszetett √Ågens Architekt√∫ra Elemz√©s - Jelenlegi √Ållapot

**D√°tum:** 2026-01-19  
**C√©l:** Analiz√°lni a jelenlegi LangGraph implement√°ci√≥t a 4-r√©teg≈± √°gens tervez√©si elvek alapj√°n

---

## üìã 4-R√©teg≈± Architekt√∫ra K√∂vetelm√©nyek

### 1. **Reasoning Layer** (LLM gondolkod√°s)
- Prompting
- Chain-of-Thought
- Triage
- Routing

### 2. **Operational Layer** (Workflow vez√©rl√©s)
- Node-ok
- Edge-ek
- State management
- Reducer pattern

### 3. **Tool Execution Layer** (K√ºls≈ë API-k)
- Adatlek√©r√©s
- Adat√≠r√°s
- Sz√°m√≠t√°s

### 4. **Memory/RAG/Context Handling**
- Stateful m≈±k√∂d√©s
- Retrieval-before-tools

---

## ‚úÖ Jelenlegi Implement√°ci√≥ √Ållapota

### **1. Reasoning Layer** - ‚ö†Ô∏è R√âSZBEN MEGVAL√ìS√çTVA

#### ‚úÖ **Prompting** - MEGVAN
- `_intent_detection_node()`: Domain klasszifik√°ci√≥ keyword-based + LLM fallback
- `_generation_node()`: RAG-based answer generation Pydantic structured output-tal
- `_memory_update_node()`: Reducer pattern prompt (merge previous + new)

**P√©lda:**
```python
# Intent detection prompt
prompt = f"""
Classify this query into ONE category:
marketing = brand, logo, visual-design
hr = vacation, employee, szabads√°g
it = VPN, computer, software
...
Provide: domain, confidence, reasoning
"""
```

#### ‚ùå **Chain-of-Thought** - HI√ÅNYZIK
Nincs explicit CoT (Step-by-Step reasoning) implement√°lva.

**Mit kellene:**
```python
# Plan node p√©lda (HI√ÅNYZIK)
async def _plan_node(self, state: AgentState) -> AgentState:
    """
    LLM thinks step-by-step:
    1. What do I need to answer this query?
    2. Which tools/data sources are needed?
    3. In what order should I execute them?
    """
    prompt = """
    Think step-by-step to answer this query:
    Query: {query}
    
    Step 1: Understand the intent
    Step 2: Identify required information
    Step 3: Choose data sources (RAG, tools, memory)
    Step 4: Plan execution order
    
    Return: execution_plan as structured JSON
    """
    # Return: {"steps": [...], "tools": [...], "data_sources": [...]}
```

#### ‚úÖ **Triage** - MEGVAN (implicit)
- `_intent_detection_node()`: Domain triage (keyword + LLM)
- `_guardrail_decision()`: Validation-based routing (retry/continue)

**P√©lda:**
```python
def _guardrail_decision(self, state: AgentState) -> str:
    """Triage: retry generation or continue to metrics."""
    validation_errors = state.get("validation_errors", [])
    retry_count = state.get("retry_count", 0)
    
    if validation_errors and retry_count < 2:
        return "retry"  # Go back to generation
    return "continue"  # Proceed to metrics
```

#### ‚úÖ **Routing** - MEGVAN
- Conditional edges: `guardrail ‚Üí generation` (retry) / `guardrail ‚Üí metrics` (continue)
- Linear routing: `intent ‚Üí retrieval ‚Üí generation ‚Üí guardrail ‚Üí metrics ‚Üí workflow ‚Üí memory ‚Üí END`

**P√©lda:**
```python
graph.add_conditional_edges(
    "guardrail",
    self._guardrail_decision,
    {
        "retry": "generation",
        "continue": "collect_metrics"
    }
)
```

#### ‚ö†Ô∏è **Hi√°nyoss√°gok:**
- ‚ùå Nincs **Plan Node** (LLM el≈ëre gondolkodik, hogy mit fog csin√°lni)
- ‚ùå Nincs **Observation Node** (LLM √©rt√©keli az intermediate results-ot)
- ‚ùå Nincs **Router Tool** (dinamikus tool selection LLM d√∂nt√©s alapj√°n)
- ‚ùå Nincs **Action/Update ciklus** (executor loop, incremental refinement)

---

### **2. Operational Layer** - ‚úÖ J√ìL MEGVAL√ìS√çTVA

#### ‚úÖ **Node-ok** - 7 node
1. `intent_detection` - Domain klasszifik√°ci√≥
2. `retrieval` - RAG Qdrant-b√≥l
3. `generation` - LLM answer generation
4. `guardrail` - Validation check
5. `collect_metrics` - Telemetria
6. `execute_workflow` - Domain-specific workflow (Jira draft)
7. `memory_update` - Reducer pattern memory

#### ‚úÖ **Edge-ek**
- **Linear edges:** 6 darab (intent‚Üíretrieval, retrieval‚Üígeneration, etc.)
- **Conditional edges:** 1 darab (guardrail‚Üíretry/continue)

#### ‚úÖ **State Management** - `AgentState` TypedDict
```python
class AgentState(TypedDict, total=False):
    messages: Sequence[BaseMessage]
    query: str
    domain: str
    retrieved_docs: list
    output: Dict[str, Any]
    citations: list
    workflow: Dict[str, Any]
    validation_errors: list
    retry_count: int
    feedback_metrics: Dict[str, Any]
    memory_summary: str
    memory_facts: list
    rag_unavailable: bool  # Degradation flag
```

#### ‚úÖ **Reducer Pattern** - `_memory_update_node()`
- Previous summary + new messages ‚Üí merged summary
- Semantic compression (max 8 facts)

**Er≈ëss√©gek:**
- Tiszta state-based workflow
- Conditional routing implemented
- Retry logic guardrail-ben

**Hi√°nyoss√°gok:**
- ‚ùå Nincs **Executor Loop** (iterat√≠v finom√≠t√°s t√∂bb LLM call-lal)
- ‚ùå Nincs **Dynamic Tool Selection** (LLM choose tools at runtime)

---

### **3. Tool Execution Layer** - ‚ö†Ô∏è MINIM√ÅLIS

#### ‚úÖ **Adatlek√©r√©s (RAG)** - MEGVAN
- `_retrieval_node()`: Qdrant vector DB query
- Timeout + retry wrapper (`with_timeout_and_retry`)

```python
citations = await with_timeout_and_retry(
    self.rag_client.retrieve_for_domain(
        domain=state["domain"],
        query=augmented_query,
        top_k=5
    ),
    timeout=settings.RAG_TIMEOUT,
    max_retries=3
)
```

#### ‚ö†Ô∏è **Adat√≠r√°s (Jira Ticket)** - R√âSZBEN MEGVAN
- `_workflow_node()`: Jira ticket draft k√©sz√≠t√©s
- `create_jira_ticket_from_draft()`: T√©nyleges Jira API h√≠v√°s (k√ºl√∂n endpoint)

**Probl√©ma:** Nincs √°ltal√°nos tool execution framework.

#### ‚ùå **Sz√°m√≠t√°s (Custom Tools)** - HI√ÅNYZIK
Nincs implement√°lt tool registry, dinamikus tool selection, vagy executor pattern.

**Mit kellene (p√©lda):**
```python
# Tool registry (HI√ÅNYZIK)
AVAILABLE_TOOLS = {
    "search_documents": qdrant_search_tool,
    "create_jira_ticket": jira_create_tool,
    "send_email": email_tool,
    "calculate_cost": cost_calculator_tool,
    "check_calendar": calendar_tool,
}

# Tool executor node (HI√ÅNYZIK)
async def _tool_executor_node(self, state: AgentState) -> AgentState:
    """Execute tools selected by LLM."""
    tool_calls = state.get("tool_calls", [])
    results = []
    
    for tool_call in tool_calls:
        tool_name = tool_call["name"]
        tool_args = tool_call["arguments"]
        
        if tool_name in AVAILABLE_TOOLS:
            result = await AVAILABLE_TOOLS[tool_name](**tool_args)
            results.append(result)
    
    state["tool_results"] = results
    return state
```

**Hi√°nyoss√°gok:**
- ‚ùå Nincs **Tool Registry** (el√©rhet≈ë tools katal√≥gus)
- ‚ùå Nincs **Dynamic Tool Selection** (LLM v√°laszt runtime-ban)
- ‚ùå Nincs **Tool Executor Loop** (t√∂bbsz√∂r√∂s tool h√≠v√°s refinement-tel)
- ‚ùå Nincs **Tool Observation** (LLM √©rt√©keli a tool eredm√©ny√©t)

---

### **4. Memory/RAG/Context Handling** - ‚úÖ J√ìL MEGVAL√ìS√çTVA

#### ‚úÖ **Stateful M≈±k√∂d√©s** - MEGVAN
- `AgentState`: Minden state mez≈ë perziszt√°lva a graph fut√°s alatt
- `messages`: Conversation history rolling window (max 8)
- `memory_summary`: Reducer pattern (previous + new)
- `memory_facts`: Semantic compression (max 8 facts)

#### ‚úÖ **Retrieval-Before-Tools** - MEGVAN
- `retrieval` node fut EL≈êBB mint `generation`
- RAG context be√©p√ºl a generation prompt-ba

```python
# Retrieval ‚Üí Generation pipeline
graph.add_edge("retrieval", "generation")

# Generation prompt tartalmazza a RAG context-et
context_parts = [
    f"Doc: {c.title}\nContent: {c.content[:500]}"
    for c in state.get("retrieved_docs", [])
]
context = "\n\n".join(context_parts)
```

#### ‚úÖ **Reducer Pattern Memory** - MEGVAN
- Previous summary + new conversation ‚Üí merged summary
- Semantic fact compression (LLM-based filtering)

**Er≈ëss√©gek:**
- Rolling window memory (8 messages)
- Semantic compression (max 8 facts)
- Reducer pattern (cumulative summary)
- RAG-first architecture

**Hi√°nyoss√°gok:**
- ‚ùå Nincs **Long-Term Memory** (persistent storage, user profiles)
- ‚ùå Nincs **Multi-Level Summarization** (short/medium/long conversation tiers)

---

## üîç Hi√°nyoss√°gok √ñsszefoglal√°sa

### **Reasoning Layer Gaps:**
1. ‚ùå **Plan Node** - LLM el≈ëre megtervezi a l√©p√©seket
2. ‚ùå **Chain-of-Thought** - Explicit step-by-step reasoning
3. ‚ùå **Observation Node** - LLM √©rt√©keli az intermediate results-ot
4. ‚ùå **Router Tool Node** - Dinamikus tool selection LLM d√∂nt√©s alapj√°n

### **Operational Layer Gaps:**
5. ‚ùå **Executor Loop** - Iterat√≠v finom√≠t√°s t√∂bb LLM call-lal (pl. plan ‚Üí execute ‚Üí observe ‚Üí replan)

### **Tool Execution Layer Gaps:**
6. ‚ùå **Tool Registry** - El√©rhet≈ë tools katal√≥gus
7. ‚ùå **Dynamic Tool Selection** - LLM choose tools at runtime
8. ‚ùå **Tool Executor Node** - √Åltal√°nos tool execution framework
9. ‚ùå **Tool Observation** - LLM √©rt√©keli tool eredm√©ny√©t, d√∂nt next action-r≈ël

### **Memory/RAG/Context Gaps:**
10. ‚ùå **Long-Term Memory** - Persistent user profiles, preferences
11. ‚ùå **Multi-Level Summarization** - Short/medium/long conversation tiers

---

## üìä Jelenlegi vs Ide√°lis Architekt√∫ra

### **Jelenlegi Workflow (7 nodes, 1 conditional edge):**
```
User Query
    ‚Üì
Intent Detection (keyword + LLM)
    ‚Üì
Retrieval (Qdrant RAG)
    ‚Üì
Generation (LLM + RAG context)
    ‚Üì
Guardrail (validation check)
    ‚Üì (retry if errors)
Collect Metrics (telemetria)
    ‚Üì
Execute Workflow (Jira draft)
    ‚Üì
Memory Update (reducer pattern)
    ‚Üì
END
```

### **Ide√°lis Workflow (with missing components):**
```
User Query
    ‚Üì
[NEW] Plan Node (LLM thinks: what do I need?)
    ‚Üì
Intent Detection (triage)
    ‚Üì
[NEW] Router Tool (LLM selects: RAG? API? Calculation?)
    ‚Üì
Retrieval (if needed)
    ‚Üì
[NEW] Tool Executor Loop (execute selected tools)
    ‚Üì
[NEW] Observation Node (LLM evaluates: good enough?)
    ‚Üì (if not ‚Üí replan)
Generation (LLM synthesizes final answer)
    ‚Üì
Guardrail (validation)
    ‚Üì
Collect Metrics
    ‚Üì
Execute Workflow
    ‚Üì
Memory Update
    ‚Üì
END
```

---

## üéØ Fejleszt√©si Javaslatok

### **High Priority (Reasoning Layer b≈ëv√≠t√©s):**

#### 1. **Plan Node** - LLM el≈ëzetes tervez√©s
```python
async def _plan_node(self, state: AgentState) -> AgentState:
    """LLM generates execution plan."""
    prompt = """
    Think step-by-step to answer this query:
    Query: {query}
    Domain: {domain}
    
    Available tools:
    - search_documents (RAG)
    - create_jira_ticket
    - send_email
    - calculate_cost
    
    Plan your approach:
    1. What information do I need?
    2. Which tools should I use?
    3. In what order?
    
    Return structured plan: {{"steps": [...], "tools": [...]}}
    """
    # LLM structured output ‚Üí ExecutionPlan model
    plan = await self.llm.with_structured_output(ExecutionPlan).ainvoke(...)
    state["execution_plan"] = plan
    return state
```

#### 2. **Tool Executor Loop** - Iterat√≠v tool execution
```python
async def _tool_executor_loop_node(self, state: AgentState) -> AgentState:
    """Execute tools iteratively with observation."""
    plan = state["execution_plan"]
    results = []
    
    for step in plan["steps"]:
        # Execute tool
        tool_result = await execute_tool(step["tool"], step["args"])
        results.append(tool_result)
        
        # Observation: LLM evaluates result
        observation_prompt = f"""
        Tool: {step['tool']}
        Result: {tool_result}
        
        Is this sufficient to answer the query?
        - If YES ‚Üí proceed to next step
        - If NO ‚Üí suggest refinement
        """
        observation = await self.llm.ainvoke(...)
        
        if observation["needs_refinement"]:
            # Replan (close the loop)
            state["execution_plan"] = await self._plan_node(state)
    
    state["tool_results"] = results
    return state
```

#### 3. **Observation Node** - Intermediate result evaluation
```python
async def _observation_node(self, state: AgentState) -> AgentState:
    """LLM evaluates intermediate results."""
    tool_results = state.get("tool_results", [])
    
    prompt = f"""
    Query: {state['query']}
    Tools executed: {len(tool_results)}
    Results: {tool_results}
    
    Evaluate:
    1. Do I have enough information to answer?
    2. Are there any gaps or contradictions?
    3. Should I execute more tools or proceed to generation?
    
    Return: {{"sufficient": bool, "next_action": str, "reasoning": str}}
    """
    
    evaluation = await self.llm.with_structured_output(ObservationOutput).ainvoke(...)
    state["observation"] = evaluation
    return state
```

### **Medium Priority (Tool Execution b≈ëv√≠t√©s):**

#### 4. **Tool Registry** - K√∂zpontos√≠tott tool katal√≥gus
```python
# tools/registry.py
from typing import Callable, Dict

class ToolRegistry:
    def __init__(self):
        self.tools: Dict[str, Callable] = {}
    
    def register(self, name: str, description: str):
        def decorator(func: Callable):
            self.tools[name] = {
                "function": func,
                "description": description,
                "schema": extract_schema(func)  # Auto-generate from type hints
            }
            return func
        return decorator
    
    def get_tool_descriptions(self) -> str:
        """Return tool descriptions for LLM prompt."""
        return "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.tools.items()
        ])

# Usage
tool_registry = ToolRegistry()

@tool_registry.register("search_documents", "Search knowledge base documents")
async def search_documents(query: str, domain: str, top_k: int = 5) -> List[Citation]:
    return await qdrant_client.retrieve_for_domain(domain, query, top_k)

@tool_registry.register("create_jira_ticket", "Create IT support ticket")
async def create_jira_ticket(summary: str, description: str) -> Dict:
    return await atlassian_client.create_ticket(summary, description)
```

#### 5. **Dynamic Tool Selection** - LLM v√°laszt runtime-ban
```python
async def _tool_selection_node(self, state: AgentState) -> AgentState:
    """LLM selects which tools to use."""
    available_tools = tool_registry.get_tool_descriptions()
    
    prompt = f"""
    Query: {state['query']}
    Available tools:
    {available_tools}
    
    Select which tools you need and in what order.
    Return: {{"tools": [{{"name": str, "arguments": dict}}]}}
    """
    
    selection = await self.llm.with_structured_output(ToolSelection).ainvoke(...)
    state["tool_calls"] = selection["tools"]
    return state
```

### **Low Priority (Memory b≈ëv√≠t√©s):**

#### 6. **Long-Term Memory** - Persistent user profiles
```python
# infrastructure/user_memory.py
class UserMemoryStore:
    def __init__(self, postgres_client):
        self.db = postgres_client
    
    async def get_user_profile(self, user_id: str) -> Dict:
        """Load user preferences, history, facts."""
        return await self.db.fetch_one(
            "SELECT * FROM user_profiles WHERE user_id = $1", user_id
        )
    
    async def update_user_facts(self, user_id: str, new_facts: List[str]):
        """Append new facts to user profile."""
        await self.db.execute(
            "UPDATE user_profiles SET facts = facts || $1 WHERE user_id = $2",
            new_facts, user_id
        )
```

---

## üìà Implement√°ci√≥s √útemterv

### **F√°zis 1 (1-2 h√©t): Reasoning Layer alapok**
1. Plan Node implement√°ci√≥
2. ExecutionPlan Pydantic model
3. Basic tool registry (3-5 tool)
4. Tool selection node (LLM-based)

### **F√°zis 2 (2-3 h√©t): Tool Execution Loop**
5. Tool executor node
6. Observation node
7. Executor loop (plan ‚Üí execute ‚Üí observe ‚Üí replan)
8. Conditional routing friss√≠t√©s

### **F√°zis 3 (1-2 h√©t): Finom√≠t√°s**
9. Long-term memory (Postgres)
10. Multi-level summarization
11. Chain-of-Thought explicit prompting
12. Performance optimaliz√°l√°s

### **F√°zis 4 (1 h√©t): Tesztel√©s**
13. Unit tesztek (√∫j node-ok)
14. Integration tesztek (executor loop)
15. Load testing (executor overhead)
16. Dokument√°ci√≥ friss√≠t√©s

---

## üéì Tanuls√°gok & Best Practices

### **Mit csin√°ltunk j√≥l:**
‚úÖ Tiszta state management (AgentState TypedDict)  
‚úÖ Reducer pattern memory (cumulative summary)  
‚úÖ Conditional routing (guardrail retry)  
‚úÖ Timeout/retry/fallback mechanizmusok  
‚úÖ Pydantic validation minden LLM output-on  

### **Mit kellene fejleszteni:**
‚ö†Ô∏è LLM el≈ëzetes tervez√©s (plan node)  
‚ö†Ô∏è Dinamikus tool selection  
‚ö†Ô∏è Executor loop (iterat√≠v finom√≠t√°s)  
‚ö†Ô∏è Tool observation (intermediate evaluation)  
‚ö†Ô∏è Long-term memory persistence  

### **Architectural Principles:**
1. **Separation of Concerns**: Reasoning ‚â† Execution ‚â† Memory
2. **Observability**: Minden node loggol + telemetria
3. **Fail-Safe**: Timeout/retry/fallback minden kritikus ponton
4. **Type Safety**: Pydantic models everywhere
5. **Idempotency**: State-based workflow, √∫jrafuttathat√≥
6. **Degradation**: RAG unavailable ‚Üí summary-only fallback

---

## üìö Referenci√°k

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [AI Agent 4-Layer Architecture](https://github.com/adrgul/ai_agent_tutorial/blob/main/docs/AI_AGENT_4_RETEG_ARCHITEKTURA.md)
- [ReAct Pattern](https://arxiv.org/abs/2210.03629) - Reasoning + Acting
- [Plan-and-Execute Pattern](https://blog.langchain.dev/planning-agents/)
- [Tool Use Best Practices](https://docs.anthropic.com/en/docs/agents/overview)

---

**K√∂vetkez≈ë l√©p√©s:** Implement√°ljuk a Plan Node-ot √©s Tool Selection Node-ot (F√°zis 1).
