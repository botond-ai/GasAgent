# KnowledgeRouter - VÃ¡llalati TudÃ¡sirÃ¡nyÃ­tÃ³ & Workflow-Automata

**Version:** 2.12.0 (STRICT_RAG_MODE Feature)  
**Status:** âœ… Stable (Configurable RAG strictness 2026-01-23)

Multi-domain AI agent rendszer Python Django backenddel, LangGraph orchestrÃ¡ciÃ³val Ã©s modern Tailwind CSS frontenddel (ChatGPT-style UI).

---

## ğŸ› KRITIKUS BUGFIXEK (v2.9.0)

**Emergency Production Fixes:**
- âœ… LangChain `with_structured_output()` bug â†’ Manual JSON parsing (6 nodes affected)
- âœ… LangGraph state management violations â†’ Decision functions now read-only
- âœ… Node name conflicts â†’ "observation" â†’ "observation_check"
- âœ… None-safe replan counter â†’ Handles None values
- âœ… Recursion limit increased â†’ 50 (supports replanning workflows)
- âœ… IT domain Jira question â†’ Auto-appended (guaranteed UX)

**See**: [docs/hÃ¡zi feladatok/3.md](./docs/hÃ¡zi%20feladatok/3.md#kritikus-bugfixek-2026-01-21) for technical details.

---

## ğŸ¯ Projekt ÃttekintÃ©se

KnowledgeRouter egy vÃ¡llalati belsÅ‘ tudÃ¡sbÃ¡zis rendszer, amely:

âœ… **LangGraph StateGraph orchestration** - 11 node-os workflow (intent â†’ plan â†’ select_tools â†’ conditional â†’ retrieval/tool_executor â†’ observation_check â†’ generation â†’ guardrail â†’ feedback_metrics â†’ workflow â†’ memory_update) **+ Replan Loop** â†º  
âœ… **6 domain-re** szÃ©tvÃ¡lasztott tudÃ¡sbÃ¡zisokbÃ³l keres (HR, IT, Finance, Legal, Marketing, General)  
âœ… **Multi-domain Qdrant collection** domain-specifikus szÅ±rÃ©ssel (egyetlen collection, gyors filtering)  
âœ… **Hibrid keresÃ©s support** szemantikus (dense vectors) + domain filtering (lexikÃ¡lis BM25 ready)  
âœ… **Intent detection** segÃ­tsÃ©gÃ©vel felismeri, melyik domain-hez tartozik a kÃ©rdÃ©s (LangGraph node)  
âœ… **RAG (Retrieval-Augmented Generation)** hasznÃ¡l relevÃ¡ns dokumentumok megtalÃ¡lÃ¡sÃ¡hoz (LangGraph node)  
âœ… **Confluence/Jira integrÃ¡ciÃ³** IT Policy auto-sync section ID tracking-gel  
âœ… **Google Drive integrÃ¡ciÃ³** marketing dokumentumok auto-sync-hez  
âœ… **Redis L1/L2 cache** embedding + query result cache (54% hit rate)  
âœ… **PostgreSQL feedback system** like/dislike rangsorolÃ¡shoz  
âœ… **Content deduplication** PDF/DOCX duplikÃ¡tumok eltÃ¡volÃ­tÃ¡sa  
âœ… **IT domain overlap boost** lexikÃ¡lis token matching (0-20% boost)  
âœ… **Feedback-weighted ranking** tiered boost system (>70%: +30%, <40%: -20%)  
âœ… **Workflow-okat** futtat (HR szabadsÃ¡g igÃ©nylÃ©s, IT ticket, stb.) - LangGraph workflow node  
âœ… **CitÃ¡ciÃ³kkal** ellÃ¡tott vÃ¡laszokat ad (section ID format: IT-KB-234)  
âœ… **Enhanced citation display** - Card layout relevancia score-ral (%), section ID, hover effect  
âœ… **KonverzÃ¡ciÃ³ elÅ‘zmÃ©nyt** mentesÃ­t JSON-ban  
âœ… **Docker Compose** multi-container (backend, frontend, qdrant, redis, postgres)  
ğŸ†• **SOLID architektÃºra** ABC interfÃ©szekkel  
ğŸ†• **Health check rendszer** startup validÃ¡lÃ¡ssal (OpenAI, Qdrant, Redis, Postgres)  
ğŸ†• **Debug CLI** vizuÃ¡lis RAG testing eszkÃ¶zÃ¶kkel  
ğŸ†• **Telemetria debug panel** - Pipeline latency, RAG context, LLM prompt/response monitoring
ğŸ†• **Guardrail Node** (v2.5) - IT domain citation validation with automatic retry logic (max 2x)
ğŸ†• **Feedback Metrics Node** (v2.5) - Telemetry collection: retrieval quality, latency, cache hits
ğŸ†• **Memory (v2.6)** - Rolling window, conversation summary, facts extraction (non-blocking)
ğŸ†• **Memory Reducer Pattern (v2.7)** - Cumulative memory summarization with semantic fact compression (previous + new â†’ merged summary, max 8 relevant facts)
ğŸ†• **Request Idempotency (v2.7)** - X-Request-ID header support with Redis cache (5 min TTL) - duplicate requests return cached response instantly
ğŸ†• **Optional MCP Server (v0.1 alpha)** - Model Context Protocol wrapper exposing Jira/Qdrant/Postgres tools (stdio); run via `pip install -r backend/mcp_server/requirements.txt && python -m backend.mcp_server`
ğŸ†• **Tool Executor Loop (v2.8)** - Iterative tool execution with asyncio timeout (10s/tool), ToolResult validation, non-blocking error handling
ğŸ†• **Observation Node + Replan Loop (v2.8)** - LLM-based evaluation: sufficient info? â†’ generate OR replan (max 2x), gap detection, automatic replanning
ğŸ”§ **Production Hardened (v2.9)** - Manual JSON parsing, state management fixes, 50 recursion limit, IT domain UX guarantee
ğŸš€ **Dual Pipeline Modes (v2.10)** - USE_SIMPLE_PIPELINE feature flag: Simple (15 sec, RAG-only) vs Complex (30-50 sec, full LangGraph with replan/tools/workflows)
ğŸ†• **STRICT_RAG_MODE Feature Flag (v2.12)** - Configurable RAG behavior: `true` = refuse without context (original), `false` = allow LLM general knowledge with âš ï¸ warning prefix

## ğŸ“‹ Tech Stack

- **Backend**: Python 3.11+ | Django | **LangGraph (StateGraph orchestration)**
- **LLM**: OpenAI GPT-4o Mini (gpt-4o-mini) | **Manual JSON parsing** (LangChain structured_output bypassed)
- **Embedding**: OpenAI text-embedding-3-small (1536 dim)
- **Vector DB**: Qdrant (self-hosted)
- **Cache**: Redis 7 (embedding + query result cache)
- **Database**: PostgreSQL 15 (feedback & analytics)
- **Monitoring**: Prometheus + Grafana (metrics, dashboards, cost tracking)
- **Logging**: Loki + Promtail (structured JSON logs, LogQL queries, log aggregation)
- **Frontend**: Tailwind CSS + Vanilla JavaScript (ChatGPT-style UI)
- **Deployment**: Docker Compose (7 services: backend, frontend, qdrant, redis, postgres, prometheus, grafana, loki, promtail)
- **Testing**: pytest (200+ tests, 54% coverage)
  - **RAG Optimization**: 27 tests (deduplication, IT overlap boost, integration)
  - **Feedback Ranking**: 15 tests (boost calculation, batch ops)
  - **Error Handling**: 39 tests (retry, token limits)
  - **Tool Executor Loop**: 6 tests (timeout, error, multi-tool)
  - **Observation + Replan**: 6 tests (LLM evaluation, replan routing, max limit)
  - **Integration E2E**: 7 tests (complete workflow, replan loop)
  - **Monitoring**: 22 tests (metrics API, collection, edge cases)
  - **Logging**: 16 tests (structured logging, JSON format, LogContext, Loki integration)
  - **Coverage Highlights**:
    - `openai_clients.py`: **100%** âœ…
    - `tool_registry.py`: **100%** âœ…
    - `structured_logging.py`: **91%** âœ…
    - `prometheus_metrics.py`: **86%** âœ…
    - `qdrant_rag_client.py`: **70%** (up from 18%)
    - `atlassian_client.py`: **87%**

## ğŸš€ Quick Start (Docker)

### 1. KlÃ³n Ã©s Setup

```bash
cd benketibor
cp .env.example .env
```

### 2. API Key BeÃ¡llÃ­tÃ¡sa

```bash
# .env fÃ¡jl szerkesztÃ©se:
nano .env
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small

# Pipeline Mode (opcionÃ¡lis):
USE_SIMPLE_PIPELINE=False  # Default: Complex workflow (30-50 sec, full features)
                            # True: Simple pipeline (15 sec, RAG-only)

# Windows PowerShell pÃ©lda:
$env:OPENAI_API_KEY = "sk-proj-..."; $env:OPENAI_MODEL = "gpt-4o-mini"; $env:EMBEDDING_MODEL = "text-embedding-3-small"; $env:USE_SIMPLE_PIPELINE = "False"
```

**Pipeline Modes:**
- **Simple (True)**: Fast RAG-only pipeline (~15 sec), ideal for IT/Marketing simple queries
- **Complex (False)**: Full LangGraph workflow (~30-50 sec) with replan loop, tool execution, workflow automation
- **See**: [docs/PIPELINE_MODES.md](docs/PIPELINE_MODES.md) for detailed comparison

### 3. Docker Compose IndÃ­tÃ¡sa

```bash
docker-compose up --build
```

**Fontos:** Az alkalmazÃ¡s **Qdrant-alapÃº RAG-et** hasznÃ¡l multi-domain collection-nel OpenAI embeddinggel (text-embedding-3-small, 1536 dim).

### 4. Dokumentumok IndexelÃ©se

#### Marketing/HR/General Domainek (Google Drive)
```bash
cd backend

# Marketing dokumentumok indexelÃ©se
python scripts/sync_domain_docs.py --domain marketing --folder-id 1Jo5doFrRgTscczqR0c6bsS2H0a7pS2ZR

# HR dokumentumok
python scripts/sync_domain_docs.py --domain hr --folder-id YOUR_HR_FOLDER_ID

# Finance/Legal/General
python scripts/sync_domain_docs.py --domain finance --folder-id YOUR_FINANCE_FOLDER_ID
```

#### IT Domain (Confluence + Jira)
**âš ï¸ IT domain speciÃ¡lis architektÃºrÃ¡val rendelkezik:**
- **Confluence indexelÃ©s** (egy alkalommal vagy periodikusan): Confluence IT Policy â†’ Qdrant semantic search
- **Jira integrÃ¡ciÃ³** (runtime): Chat-based Jira ticket creation ("igen" response)

```bash
# Confluence IT Policy indexelÃ©se Qdrant-ba
docker-compose exec backend python scripts/sync_confluence_it_policy.py --clear

# EllenÅ‘rzÃ©s: Qdrant Dashboard http://localhost:6334/dashboard
# Collection: multi_domain_kb, Filter: domain="it"
```

**IT Domain kÃ¶rnyezeti vÃ¡ltozÃ³k (.env):**
```bash
CONFLUENCE_BASE_URL=https://your-company.atlassian.net/wiki
CONFLUENCE_API_TOKEN=your_confluence_api_token_here
JIRA_BASE_URL=https://your-company.atlassian.net
JIRA_API_TOKEN=your_jira_api_token_here
ATLASSIAN_EMAIL=your-email@company.com
```

**IT Domain workflow:**
1. User query: "VPN problÃ©mÃ¡m van" â†’ Intent detection (`domain=it`)
2. Qdrant retrieval: Semantic search (domain filter `it`)
3. LLM generation: IT policy alapjÃ¡n vÃ¡lasz + Jira ticket offer
4. User response: "igen" â†’ Frontend detects confirmation
5. Jira ticket creation: POST `/api/jira/ticket/` â†’ SCRUM project

RÃ©szletek: [docs/IT_DOMAIN_IMPLEMENTATION.md](docs/IT_DOMAIN_IMPLEMENTATION.md)

RÃ©szletek: [ğŸ§  RAG & Embedding Rendszer ArchitektÃºra](#-rag--embedding-rendszer-architektÃºra)

### 5. HozzÃ¡fÃ©rÃ©s

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8001/api/
- **Qdrant Dashboard**: http://localhost:6334 (vector DB)
- **Redis**: localhost:6380 (cache)
- **Cache Stats**: http://localhost:8001/api/cache-stats/
- **Google Drive Files API**: http://localhost:8001/api/google-drive/files/

### 5. Google Drive Setup (opcionÃ¡lis)

A marketing domain Google Drive integrÃ¡ciÃ³hoz lÃ¡sd: [docs/GOOGLE_DRIVE_SETUP.md](docs/GOOGLE_DRIVE_SETUP.md)

## ğŸ® PrÃ³ba KÃ©rÃ©sek

Nyisd meg a frontend-et Ã©s prÃ³bÃ¡ld ezeket:

### HR Domain
```
"SzeretnÃ©k szabadsÃ¡got igÃ©nyelni oktÃ³ber 3-4-re"
"Mi a szabadsÃ¡g politika?"
"MunkaadÃ³ tÃ¡mogatÃ¡sok?"
```

### IT Domain
```
"VPN problÃ©mÃ¡m van, mi a teendÅ‘?"
"Hogyan telepÃ­tsem fel a VPN klienst?"
"JelszÃ³ visszaÃ¡llÃ­tÃ¡s lÃ©pÃ©sei?"
"SzeretnÃ©k Jira ticketet lÃ©trehozni" â†’ "igen" (chat-based flow)
```

**IT Domain architecture:**
- **Confluence â†’ Qdrant**: IT Policy indexed via `sync_confluence_it_policy.py`
- **Semantic search**: Qdrant retrieval with `domain=it` filter (NOT keyword matching)
- **Jira integration**: Chat-based ticket creation ("igen" response triggers Jira API)
- Details: [docs/IT_DOMAIN_IMPLEMENTATION.md](docs/IT_DOMAIN_IMPLEMENTATION.md)

### Marketing Domain
```
"Hol van a brand guideline?"
"Legfrissebb marketing dokumentumok?"
```

## ğŸ“ Projekt StruktÃºra

```
benketibor/
â”œâ”€â”€ backend/                      # Django + LangGraph
â”‚   â”œâ”€â”€ core/                    # Django settings & config
â”‚   â”‚   â”œâ”€â”€ settings.py          # App konfigurciÃ³
â”‚   â”‚   â”œâ”€â”€ urls.py              # URL routing
â”‚   â”‚   â”œâ”€â”€ wsgi.py / asgi.py    # WSGI/ASGI entry
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ domain/                  # Business logic models
â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic data models (Citation, QueryResponse, etc.)
â”‚   â”‚   â”œâ”€â”€ interfaces.py        # Abstract base classes (IRAGClient, IFeedbackStore)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ infrastructure/          # External integrations & clients
â”‚   â”‚   â”œâ”€â”€ qdrant_rag_client.py    # Qdrant vector DB client (hybrid search, dedup, boost)
â”‚   â”‚   â”œâ”€â”€ postgres_client.py      # PostgreSQL feedback storage (lazy init, batch ops)
â”‚   â”‚   â”œâ”€â”€ redis_client.py         # Redis L1/L2 cache (embedding + query cache)
â”‚   â”‚   â”œâ”€â”€ openai_clients.py       # OpenAI LLM + Embeddings (singleton factory)
â”‚   â”‚   â”œâ”€â”€ atlassian_client.py     # Confluence/Jira API (IT Policy sync)
â”‚   â”‚   â”œâ”€â”€ google_drive_client.py  # Google Drive API (marketing docs)
â”‚   â”‚   â”œâ”€â”€ repositories.py         # File-based storage (users, sessions)
â”‚   â”‚   â”œâ”€â”€ error_handling.py       # Retry logic, token limits, cost tracking
â”‚   â”‚   â”œâ”€â”€ health_check.py         # Startup validation (OpenAI, Qdrant, Postgres, Redis)
â”‚   â”‚   â”œâ”€â”€ rag_client.py           # RAG interface (legacy, use qdrant_rag_client)
â”‚   â”‚   â”œâ”€â”€ document_parser.py      # Document parsing utilities
â”‚   â”‚   â”œâ”€â”€ schema.sql              # PostgreSQL schema (feedback table)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ agent.py             # LangGraph agent (StateGraph: intent â†’ plan â†’ select_tools â†’ tool_executor/retrieval â†’ generation â†’ guardrail â†’ feedback_metrics â†’ workflow â†’ memory_update)
â”‚   â”‚   â”œâ”€â”€ chat_service.py      # Chat orchestration
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/                     # API endpoints
â”‚   â”‚   â”œâ”€â”€ views.py             # REST views (/api/query/, /api/sessions/, /api/feedback/)
â”‚   â”‚   â”œâ”€â”€ urls.py              # API URLs
â”‚   â”‚   â”œâ”€â”€ apps.py              # App initialization & health checks
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ scripts/                 # Maintenance & indexing scripts
â”‚   â”‚   â”œâ”€â”€ sync_confluence_it_policy.py   # Index IT Policy to Qdrant
â”‚   â”‚   â”œâ”€â”€ sync_marketing_docs.py         # Index marketing docs from Google Drive
â”‚   â”‚   â”œâ”€â”€ sync_domain_docs.py            # Generic domain sync
â”‚   â”‚   â”œâ”€â”€ create_collections.py          # Create Qdrant collections
â”‚   â”‚   â”œâ”€â”€ migrate_to_multi_domain.py     # Migration utilities
â”‚   â”‚   â”œâ”€â”€ authenticate_google_drive.py   # Google Drive OAuth
â”‚   â”‚   â”œâ”€â”€ ingest_documents.py            # Bulk document ingestion
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ tests/                   # Unit & integration tests (180 tests, 53% coverage)
â”‚   â”‚   â”œâ”€â”€ test_qdrant_deduplication.py   # Deduplication & IT overlap boost (21 tests)
â”‚   â”‚   â”œâ”€â”€ test_qdrant_integration.py     # E2E RAG pipeline (6 tests)
â”‚   â”‚   â”œâ”€â”€ test_feedback_ranking.py       # Feedback boost calculation (4 tests)
â”‚   â”‚   â”œâ”€â”€ test_postgres_client.py        # Lazy init & batch ops (8 tests)
â”‚   â”‚   â”œâ”€â”€ test_integration_feedback.py   # Feedback integration (3 tests)
â”‚   â”‚   â”œâ”€â”€ test_atlassian_client.py       # Confluence/Jira parsing
â”‚   â”‚   â”œâ”€â”€ test_error_handling.py         # Retry & token limits (39 tests)
â”‚   â”‚   â”œâ”€â”€ test_openai_clients.py         # Factory pattern (24 tests)
â”‚   â”‚   â”œâ”€â”€ test_health_check.py           # Startup validation (10 tests)
â”‚   â”‚   â”œâ”€â”€ test_debug_cli.py              # CLI formatting (17 tests)
â”‚   â”‚   â”œâ”€â”€ test_interfaces.py             # ABC contracts (15 tests)
â”‚   â”‚   â”œâ”€â”€ test_redis_cache.py            # Cache tests (11 tests)
â”‚   â”‚   â”œâ”€â”€ test_telemetry.py              # Telemetry tests (9 tests)
â”‚   â”‚   â”œâ”€â”€ conftest.py                    # Shared fixtures
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ data/                    # Persistent storage (JSON)
â”‚   â”‚   â”œâ”€â”€ users/              # User profiles
â”‚   â”‚   â”œâ”€â”€ sessions/           # Conversation histories
â”‚   â”‚   â””â”€â”€ files/              # Generated files
â”‚   â”œâ”€â”€ manage.py                # Django CLI
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ Dockerfile               # Backend container

â”œâ”€â”€ frontend/                    # Tailwind CSS + Vanilla JS
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html          # Chat UI (ChatGPT-style)
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ app.js              # Frontend logic
â”‚   â”‚   â””â”€â”€ css/
â”‚   â”‚       â””â”€â”€ style.css       # Tailwind compiled CSS
â”‚   â”œâ”€â”€ input.css               # Tailwind source
â”‚   â”œâ”€â”€ tailwind.config.js      # Tailwind configuration
â”‚   â”œâ”€â”€ package.json            # Node dependencies
â”‚   â”œâ”€â”€ nginx.conf              # Nginx configuration
â”‚   â””â”€â”€ Dockerfile              # Frontend container

â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ README.md               # Architecture overview
â”‚   â”œâ”€â”€ FEATURES.md             # Feature list (v2.4)
â”‚   â”œâ”€â”€ CHANGELOG_v2.4.md       # v2.4 release notes
â”‚   â”œâ”€â”€ IT_DOMAIN_IMPLEMENTATION.md  # IT domain architecture
â”‚   â”œâ”€â”€ API.md                  # API documentation
â”‚   â”œâ”€â”€ INSTALLATION.md         # Setup guide
â”‚   â”œâ”€â”€ FRONTEND_SETUP.md       # Frontend development
â”‚   â”œâ”€â”€ GOOGLE_DRIVE_SETUP.md   # Google Drive integration
â”‚   â”œâ”€â”€ REDIS_CACHE.md          # Cache architecture
â”‚   â””â”€â”€ INIT_PROMPT.md          # Project initialization

â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration (backend, frontend, qdrant, redis, postgres)
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ start-dev.sh               # Local dev script (bash)
```

## ğŸ”§ API VÃ©gpontok

**Teljes API dokumentÃ¡ciÃ³ Swagger formÃ¡tumban:** [docs/API.md](docs/API.md)

### POST `/api/query/`

Feldolgozz egy felhasznÃ¡lÃ³i kÃ©rdÃ©st az agent-en keresztÃ¼l multi-domain RAG Ã©s workflow tÃ¡mogatÃ¡ssal.

**Request:**
```json
{
  "user_id": "emp_001",
  "session_id": "session_abc123",
  "query": "SzeretnÃ©k szabadsÃ¡got igÃ©nyelni oktÃ³ber 3-4-re",
  "organisation": "ACME Corp"
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "domain": "hr",
    "answer": "SzabadsÃ¡gkÃ©relmed rÃ¶gzÃ­tÃ©sre kerÃ¼lt oktÃ³ber 3-4 kÃ¶zÃ¶tt. A policy szerint minimum 2 hÃ©ttel elÅ‘re kell jelezni. [HR-POL-001]",
    "citations": [
      {
        "doc_id": "HR-POL-001",
        "title": "Vacation Policy",
        "score": 0.94,
        "url": null
      }
    ],
    "workflow": {
      "action": "hr_request_draft",
      "type": "vacation_request",
      "status": "draft",
      "next_step": "manager_approval"
    }
  }
}
```

**Error Responses:**
- `400 Bad Request`: Ãœres vagy Ã©rvÃ©nytelen query
- `413 Request Too Large`: Query tÃºl hosszÃº (>10,000 tokens)
- `500 Internal Server Error`: Backend hiba
- `503 Service Unavailable`: OpenAI API elÃ©rhetetlen

### GET `/api/sessions/{session_id}/`

LekÃ©rd egy session beszÃ©lgetÃ©si elÅ‘zmÃ©nyÃ©t.

**Response:**
```json
{
  "success": true,
  "data": {
    "session_id": "session_abc123",
    "messages": [
      {
        "role": "user",
        "content": "SzeretnÃ©k szabadsÃ¡got igÃ©nyelni...",
        "timestamp": "2025-10-03T14:30:00"
      },
      {
        "role": "assistant",
        "content": "SzabadsÃ¡gkÃ©relmed rÃ¶gzÃ­tÃ©sre kerÃ¼lt...",
        "timestamp": "2025-10-03T14:30:05"
      }
    ]
  }
}
```

### POST `/api/reset-context/`

TÃ¶rÃ¶ld a session beszÃ©lgetÃ©si elÅ‘zmÃ©nyÃ©t (de a user profil megmarad).

**Request:**
```json
{
  "session_id": "session_abc123"
}
```

### GET `/api/usage-stats/`

Token hasznÃ¡lat Ã©s OpenAI API kÃ¶ltsÃ©gek lekÃ©rdezÃ©se.

**Response:**
```json
{
  "success": true,
  "data": {
    "calls": 127,
    "prompt_tokens": 45200,
    "completion_tokens": 12800,
    "total_tokens": 58000,
    "total_cost_usd": 0.0874
  },
  "message": "Token usage statistics since last reset"
}
```

### DELETE `/api/usage-stats/`

Token hasznÃ¡lat statisztikÃ¡k nullÃ¡zÃ¡sa.

**Response:**
```json
{
  "success": true,
  "message": "Usage statistics reset successfully"
}
```

### GET `/api/google-drive/files/`

Google Drive marketing folder fÃ¡jlok listÃ¡zÃ¡sa.

**Response:**
```json
{
  "success": true,
  "folder_id": "1Jo5doFrRgTscczqR0c6bsS2H0a7pS2ZR",
  "file_count": 3,
  "files": [
    {
      "id": "150jnsbIl3HreheZyiCDU3fUt9cdL_EFS",
      "name": "Aurora_Digital_Arculati_Kezikonyv_HU.pdf",
      "mimeType": "application/pdf",
      "size": "163689",
      "createdTime": "2025-12-16T13:59:26.841Z",
      "webViewLink": "https://drive.google.com/file/d/..."
    }
  ]
}
```

## ğŸŒ Environment VÃ¡ltozÃ³k

SzÃ¼ksÃ©ges `.env` fÃ¡jl:

```bash
# Django
DEBUG=True
SECRET_KEY=your-secret-key-here
ALLOWED_HOSTS=localhost,127.0.0.1,backend

# OpenAI API
OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-4o-mini

# Vector DB (Qdrant)
QDRANT_HOST=localhost
QDRANT_PORT=6334
QDRANT_COLLECTION=multi_domain_kb  # Multi-domain collection with domain filtering

# Database
DATABASE_URL=sqlite:///db.sqlite3
```

## ğŸ“ Tipikus Workflow (LangGraph StateGraph)

```
User Query â†’ LangGraph.ainvoke(initial_state)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LangGraph StateGraph Execution          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  [Node 1: Intent Detection]                     â”‚
â”‚  â””â”€ Dual-strategy classification:               â”‚
â”‚     â”œâ”€ Keyword match (primary): "brand" â†’ mkt   â”‚
â”‚     â””â”€ LLM fallback (GPT-4o-mini): complex      â”‚
â”‚  â””â”€ Domains: HR/IT/Finance/Legal/Marketing/Gen  â”‚
â”‚  â””â”€ Update state: domain = "marketing"          â”‚
â”‚                     â†“                           â”‚
â”‚  [Node 2: Retrieval]                            â”‚
â”‚  â””â”€ Search Qdrant with domain filter            â”‚
â”‚     â”œâ”€ Domain filter: {"domain": "marketing"}   â”‚
â”‚     â”œâ”€ Semantic search: COSINE similarity       â”‚
â”‚     â””â”€ Top-K chunks returned                    â”‚
â”‚  â””â”€ Update state: citations = [...]             â”‚
â”‚                     â†“                           â”‚
â”‚  [Node 3: Generation]                           â”‚
â”‚  â””â”€ LLM generates answer with citations         â”‚
â”‚  â””â”€ Token limit protection (100k max)           â”‚
â”‚  â””â”€ Update state: output = {...}                â”‚
â”‚                     â†“                           â”‚
â”‚  [Node 4: Workflow Execution]                   â”‚
â”‚  â””â”€ Execute domain-specific action (if needed)  â”‚
â”‚  â””â”€ HR vacation request / IT ticket creation    â”‚
â”‚  â””â”€ Update state: workflow = {...}              â”‚
â”‚                     â†“                           â”‚
â”‚                   [END]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Response + Citations + Workflow Result
    â†“
[Persistence] â†’ Save to JSON (conversation history)

### âš¡ Cached Regeneration (Optimized 2-Node Path)

User clicks âš¡ Refresh â†’ RegenerateAPIView
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       LangGraph Cached Regeneration             â”‚
â”‚       (Skip Intent + RAG, Use Cache)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  [SKIPPED: Intent Detection]                    â”‚
â”‚  â”œâ”€ Read from session: domain = "marketing"     â”‚
â”‚  â””â”€ Saves: ~100 tokens + LLM call              â”‚
â”‚                     â†“                           â”‚
â”‚  [SKIPPED: RAG Retrieval]                       â”‚
â”‚  â”œâ”€ Read from session: citations = [...]        â”‚
â”‚  â””â”€ Saves: ~1500 tokens + Qdrant query         â”‚
â”‚                     â†“                           â”‚
â”‚  [Node 3: Generation] âœ… EXECUTED                â”‚
â”‚  â””â”€ LLM regenerates with SAME cached citations  â”‚
â”‚  â””â”€ Fresh answer, consistent context            â”‚
â”‚  â””â”€ Update state: output = {...}                â”‚
â”‚                     â†“                           â”‚
â”‚  [Node 4: Workflow] âœ… EXECUTED                  â”‚
â”‚  â””â”€ Execute domain-specific action              â”‚
â”‚  â””â”€ Update state: workflow = {...}              â”‚
â”‚                     â†“                           â”‚
â”‚                   [END]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Regenerated Response (with regenerated=true flag)

**Performance Comparison:**

| Metric              | Full Pipeline (4 nodes) | Cached Regeneration (2 nodes) | Savings   |
|---------------------|-------------------------|-------------------------------|----------|
| **Execution Time**  | ~5600ms                 | ~3500ms                       | **38% faster** |
| **Token Usage**     | ~2500 tokens            | ~500 tokens                   | **80% cheaper** |
| **LLM Calls**       | 2 (intent + generation) | 1 (generation only)           | **50% less** |
| **Qdrant Queries**  | 1 (RAG retrieval)       | 0 (uses cache)                | **100% saved** |
| **Nodes Executed**  | 4 (intent â†’ RAG â†’ gen â†’ workflow) | 2 (gen â†’ workflow)   | **50% less** |

**Use Cases:**
- âš¡ **Fast refresh**: Same question, different phrasing in LLM response
- âš¡ **Retry with same context**: If answer quality not satisfactory
- ğŸ”„ **Full refresh**: Need fresh RAG results from updated documents
```

## ğŸ§  RAG & Embedding Rendszer ArchitektÃºra

### **ÃttekintÃ©s**

A KnowledgeRouter **Retrieval-Augmented Generation (RAG)** rendszert hasznÃ¡l **multi-domain** tudÃ¡sbÃ¡zis kezelÃ©sÃ©hez. A rendszer egyetlen Qdrant collection-t hasznÃ¡l (`multi_domain_kb`) domain-specifikus szÅ±rÃ©ssel, amely lehetÅ‘vÃ© teszi:

- **SkÃ¡lÃ¡zhatÃ³sÃ¡g**: Ãšj domain hozzÃ¡adÃ¡sa = Ãºj dokumentumok indexelÃ©se ugyanabba a collection-be
- **Gyors filtering**: Domain payload index â†’ milliszekundumos szÅ±rÃ©s
- **Hibrid keresÃ©s support**: Szemantikus (dense vectors) + domain filter, kÃ©szenlÃ©t lexikÃ¡lisra (BM25)

A folyamat kÃ©t fÅ‘ rÃ©szre oszlik: **offline indexelÃ©s** Ã©s **runtime lekÃ©rdezÃ©s**.

### **1. Offline IndexelÃ©s (Multi-Domain Document Ingestion)**

**CÃ©l:** BÃ¡rmilyen domain Google Drive dokumentumainak betÃ¶ltÃ©se â†’ Qdrant vektor adatbÃ¡zisba domain metadatÃ¡val

**UniverzÃ¡lis Script:** `backend/scripts/sync_domain_docs.py`

**Folyamat lÃ©pÃ©sei:**

#### **1.1 Dokumentum letÃ¶ltÃ©s**
```python
# Google Drive API-n keresztÃ¼l
drive_client = get_drive_client()
content = drive_client.download_file_content(file_id)
```

#### **1.2 SzÃ¶veg kinyerÃ©s**
```python
# PDF/DOCX â†’ tiszta szÃ¶veg
text = DocumentParser.parse_document(content, mime_type)
# Pl.: "Brand Guidelines â€“ AURORA DIGITAL\n\n1. Brand Overview..."
```

#### **1.3 Text Chunking (DarabolÃ¡s)**
```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,        # Max 800 karakter/chunk
    chunk_overlap=100,     # 100 karakter Ã¡tfedÃ©s
    separators=["\n\n", "\n", ". ", " ", ""]
)
chunks = text_splitter.split_text(text)
```

**MiÃ©rt kell chunkolni?**
- LLM-nek nem tudunk 100 oldalas dokumentumot kÃ¼ldeni (token limit)
- Kisebb darabok â†’ pontosabb keresÃ©s
- **Overlap:** BiztosÃ­tja, hogy fontos informÃ¡ciÃ³ ne vesszen el a hatÃ¡ron

#### **1.4 Embedding GenerÃ¡lÃ¡s (OpenAI)**
```python
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectors = embeddings.embed_documents([chunk["text"] for chunk in chunks])
# Minden chunk â†’ 1536 dimenziÃ³s float vektor
# Pl.: [0.234, -0.567, 0.123, ..., 0.891]
```

**Mi az embedding?**
- SzÃ¶veg matematikai reprezentÃ¡ciÃ³ja
- HasonlÃ³ jelentÃ©sÅ± szÃ¶vegek â†’ kÃ¶zeli vektorok
- "sorhossz" Ã©s "line length" â†’ kÃ¶zel azonos vektorban

#### **1.5 Qdrant-ba MentÃ©s**
```python
qdrant_client.upsert(
    collection_name="marketing",
    points=[
        PointStruct(
            id=unique_id,
            vector=embedding_vector,  # 1536 float szÃ¡m
            payload={
                "text": chunk_text,
                "source_file_name": "Aurora_Digital_Brand_Guidelines_eng.docx",
                "source_file_id": "1ACEdQxgUuAsDHKPBqKyp2kt88DjfXjhv",
                "chunk_index": 0,
                "domain": "marketing",
                "indexed_at": "2025-12-16T14:30:00Z"
            }
        )
    ]
)
```

**AdatstruktÃºra Qdrant-ban:**
| **MezÅ‘** | **Ã‰rtÃ©k pÃ©lda** | **LeÃ­rÃ¡s** |
|---|---|---|
| `id` | `uuid4()` | Egyedi chunk azonosÃ­tÃ³ |
| `vector` | `[0.234, -0.567, ...]` | 1536 dimenziÃ³s embedding |
| `payload.text` | `"A logo arÃ¡nyai..."` | Chunk szÃ¶veg tartalma |
| `payload.source_file_name` | `"Aurora_Brand_Guide.docx"` | ForrÃ¡s fÃ¡jl neve |
| `payload.chunk_index` | `0` | HÃ¡nyadik chunk a dokumentumban |

---

### **2. Runtime LekÃ©rdezÃ©s (RAG Query)**

**Komponens:** `backend/infrastructure/qdrant_rag_client.py` â†’ `QdrantRAGClient`

**Folyamat lÃ©pÃ©sei:**

#### **2.1 User Query Embedding**
```python
# User kÃ©rdÃ©s: "Mi a brand guideline sorhossz ajÃ¡nlÃ¡sa?"
query_embedding = embeddings.embed_query(query)
# â†’ [0.189, -0.623, 0.412, ..., 0.734] (1536 float)
```

#### **2.2 Szemantikus KeresÃ©s + Domain Filtering**
```python
# Domain filter lÃ©trehozÃ¡sa (csak marketing docs)
domain_filter = Filter(
    must=[
        FieldCondition(
            key="domain",
            match=MatchValue(value="marketing")
        )
    ]
)

search_results = qdrant_client.search(
    collection_name="multi_domain_kb",  # Egyetlen multi-domain collection
    query_vector=query_embedding,        # User kÃ©rdÃ©s vektora
    query_filter=domain_filter,          # Domain-specifikus szÅ±rÃ©s!
    limit=5,                             # Top 5 legkÃ¶zelebbi chunk
    with_payload=True                    # SzÃ¶veg tartalom is kell
)
```

**Hogyan mÅ±kÃ¶dik a keresÃ©s?**
- **Domain filter**: ElÅ‘szÅ±rÃ©s â†’ csak marketing dokumentumok
- **Cosine similarity**: Szemantikus hasonlÃ³sÃ¡g a szÅ±rt halmazon
- `similarity = cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)`
- Ã‰rtÃ©k: 0 (teljesen eltÃ©rÅ‘) â†’ 1 (azonos jelentÃ©s)
- Pl.: `query_vec â‰ˆ chunk_vec` â†’ magas score (0.7-0.9)
- **ElÅ‘ny**: HR kÃ©rdÃ©s nem talÃ¡l marketing anyagokat, gyorsabb keresÃ©s

#### **2.3 Citation Objektumok LÃ©trehozÃ¡sa**
```python
citations = [
    Citation(
        doc_id="1ACEdQxgUuAsDHKPBqKyp2kt88DjfXjhv#chunk2",
        title="Aurora_Digital_Brand_Guidelines_eng.docx",
        score=0.89,  # Milyen relevÃ¡ns (0-1)
        content="MaximÃ¡lis sorhossz: 70-80 karakter.\nMegfelelÅ‘ mennyisÃ©gÅ± Ã¼res tÃ©r..."
    ),
    # ... tovÃ¡bbi 4 chunk
]
```

---

### **3. LLM GenerÃ¡lÃ¡s (Context-Aware Response)**

**Komponens:** `backend/services/agent.py` â†’ `QueryAgent._generation_node`

#### **3.1 Retrieval HÃ­vÃ¡s**
```python
# Agent LangGraph node-ja
citations = await rag_client.retrieve_for_domain(
    domain="marketing",
    query="Mi a sorhossz?",
    top_k=5
)
# â†’ 5 legkÃ¶zelebbi chunk visszajÃ¶n
```

#### **3.2 Context Building**
```python
context_parts = []
for i, citation in enumerate(citations, 1):
    if i <= 3:  # Top 3: teljes tartalom
        context_parts.append(f"[Document {i}: {citation.title}]\n{citation.content}")
    else:  # 4-5: csonkÃ­tott (timeout elkerÃ¼lÃ©se)
        context_parts.append(f"[Document {i}: {citation.title}]\n{citation.content[:300]}...")

context = "\n\n".join(context_parts)
```

#### **3.3 LLM Prompt Assembly**
```python
prompt = f"""
You are a helpful Marketing assistant.

Retrieved documents (use ALL relevant information):
{context}

User query: "{query}"

Provide a comprehensive answer based on the retrieved documents above.
Use proper formatting with line breaks and bullet points.
Answer in Hungarian if the query is in Hungarian.
"""

answer = llm.invoke(prompt)
```

**PÃ©lda Generated Answer:**
```
A brand guideline sorhosszra vonatkozÃ³ javaslat:

### MaximÃ¡lis sorhossz
- **70-80 karakter** a javasolt maximÃ¡lis Ã©rtÃ©k
- MegfelelÅ‘ mennyisÃ©gÅ± Ã¼res tÃ©r alkalmazÃ¡sa kÃ¶telezÅ‘

### ElrendezÃ©s
- RÃ¡csszerkezethez igazÃ­tott layout
- FÃ¼ggÅ‘leges ritmus elÅ‘nyben rÃ©szesÃ­tÃ©se
```

---

### **4. Adatfolyam Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OFFLINE INDEXELÃ‰S (Multi-Domain)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Google Drive Docs (HR/IT/Finance/Marketing/etc.)            â”‚
â”‚                          â†“                                   â”‚
â”‚              Text Extraction â†’ Chunking                      â”‚
â”‚                          â†“                                   â”‚
â”‚          Domain Metadata Tag ({"domain": "marketing"})       â”‚
â”‚                          â†“                                   â”‚
â”‚              OpenAI Embedding (1536-d)                       â”‚
â”‚                          â†“                                   â”‚
â”‚    Qdrant multi_domain_kb (COSINE + domain payload index)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RUNTIME LEKÃ‰RDEZÃ‰S (Domain-Filtered)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User Query: "Mi a sorhossz?"                                 â”‚
â”‚       â†“                                                      â”‚
â”‚ [1] Intent Detection (keyword: "sorhossz" â†’ marketing)      â”‚
â”‚       â†“                                                      â”‚
â”‚ [2] Query Embedding (OpenAI)                                 â”‚
â”‚       â†“                                                      â”‚
â”‚ [3] Qdrant Search (Domain Filter + Cosine Similarity)       â”‚
â”‚     â”œâ”€ Filter: {"domain": "marketing"}                      â”‚
â”‚     â””â”€ Semantic: COSINE similarity, top_k=5                 â”‚
â”‚       â†“                                                      â”‚
â”‚ [4] Top 5 Chunks Retrieved (csak marketing docs!)           â”‚
â”‚   - Aurora_Brand_Guidelines_eng.docx (score: 0.89)          â”‚
â”‚   - Aurora_Arculati_Kezikonyv_HU.docx (score: 0.87)         â”‚
â”‚   - ...                                                      â”‚
â”‚       â†“                                                      â”‚
â”‚ [5] Context Building (Top 3 full, rest truncated)           â”‚
â”‚       â†“                                                      â”‚
â”‚ [6] LLM Prompt + Generation (GPT-4o-mini)                    â”‚
â”‚       â†“                                                      â”‚
â”‚ [7] Formatted Answer + Citations                             â”‚
â”‚       â†“                                                      â”‚
â”‚ [8] Frontend Rendering (Markdown â†’ HTML)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **5. Kulcs TechnolÃ³giÃ¡k**

| **Komponens** | **Szerepe** | **TechnolÃ³gia** |
|---|---|---|
| `sync_domain_docs.py` | **Multi-domain indexelÃ©s** | Google Drive API, OpenAI Embeddings, Qdrant, domain metadata |
| `sync_marketing_docs.py` | RÃ©gi marketing-specifikus indexelÃ©s | Google Drive API, OpenAI Embeddings, Qdrant |
| `QdrantRAGClient` | **Hibrid retrieval (szemantikus + domain filter)** | Qdrant Python client, COSINE similarity, payload filtering |
| `QueryAgent._retrieval_node` | RAG orchestration | LangGraph workflow |
| `QueryAgent._generation_node` | Context-aware LLM generÃ¡lÃ¡s | OpenAI GPT-4o-mini |
| Qdrant Database | Vektor tÃ¡rolÃ¡s + domain indexelÃ©s | In-memory vector DB (Docker), payload index |
| LangChain Text Splitter | Chunking | RecursiveCharacterTextSplitter |
| OpenAI Embeddings | SzÃ¶veg â†’ vektor | `text-embedding-3-small` (1536-d) |

---

### **6. MiÃ©rt MÅ±kÃ¶dik JÃ³l?**

âœ… **Szemantikus keresÃ©s**: Nem keyword match, hanem jelentÃ©s alapÃº
   - "sorhossz", "line length", "character limit" â†’ azonos vektorban

âœ… **Domain-specifikus szÅ±rÃ©s**: Csak relevÃ¡ns tudÃ¡sbÃ¡zisban keres
   - HR kÃ©rdÃ©s â†’ csak HR dokumentumok
   - Marketing kÃ©rdÃ©s â†’ csak marketing dokumentumok
   - Gyors payload index â†’ ms-os szÅ±rÃ©s

âœ… **Chunking stratÃ©gia**: Nagy dokumentumok â†’ kezelhetÅ‘ darabok
   - 800 char chunks + 100 char overlap
   - Natural separators: `\n\n`, `\n`, `. `

âœ… **Hibrid keresÃ©s kÃ©szenlÃ©t**: 
   - Jelenleg: Szemantikus (dense vectors) + domain filter
   - JÃ¶vÅ‘: + LexikÃ¡lis (sparse vectors/BM25) mÃ¡rkanevek, kÃ³dok esetÃ©n

âœ… **Top-K ranking**: Csak relevÃ¡ns informÃ¡ciÃ³k kerÃ¼lnek az LLM-nek
   - 5 legjobb chunk (0.4-0.9 score)
   - Timeout elkerÃ¼lÃ©se: Top 3 full content, rest truncated

âœ… **Domain detection**: Marketing queries â†’ marketing collection
   - Keyword-based pre-classification (20+ terms)
   - LLM fallback Ã¡ltalÃ¡nos esetekre

âœ… **Citation tracking**: Minden chunk forrÃ¡sa nyomon kÃ¶vethetÅ‘
   - `source_file_name` â†’ Frontend "ForrÃ¡sok" megjelenÃ­tÃ©s
   - `chunk_index` â†’ Pontos hivatkozÃ¡s a dokumentumon belÃ¼l
   - **`domain`** â†’ Domain szÅ±rÃ©s (hr, it, finance, marketing, stb.)

---

### **7. IndexelÃ©s FuttatÃ¡sa**

#### **UniverzÃ¡lis Multi-Domain IndexelÃ©s (ÃšJ)**

Az Ãºj `sync_domain_docs.py` script bÃ¡rmilyen domainhez tud dokumentumokat indexelni:

```bash
# Marketing dokumentumok
cd backend
python scripts/sync_domain_docs.py --domain marketing --folder-id 1Jo5doFrRgTscczqR0c6bsS2H0a7pS2ZR

# HR dokumentumok (pÃ©lda)
python scripts/sync_domain_docs.py --domain hr --folder-id YOUR_HR_FOLDER_ID

# IT dokumentumok (pÃ©lda)
python scripts/sync_domain_docs.py --domain it --folder-id YOUR_IT_FOLDER_ID

# Finance dokumentumok (pÃ©lda)
python scripts/sync_domain_docs.py --domain finance --folder-id YOUR_FINANCE_FOLDER_ID
```

**Kimenet:**
```
ğŸš€ Starting Domain Documents Sync
ğŸ·ï¸  Domain: MARKETING
ğŸ“‚ Google Drive Folder: 1Jo5doFrRgTscczqR0c6bsS2H0a7pS2ZR
ğŸ—„ï¸  Qdrant Collection: multi_domain_kb
ğŸ“Š Qdrant: localhost:6333

âœ… Collection 'multi_domain_kb' created with domain index
ğŸ“¥ Downloading: Aurora_Digital_Brand_Guidelines_eng.docx
ğŸ“„ Parsing: Aurora_Digital_Brand_Guidelines_eng.docx
âœ… Extracted 5234 characters
âœ‚ï¸  Split into 7 chunks (domain=marketing)
ğŸ§  Generating embeddings for 7 chunks...
âœ… Generated 7 embeddings
â¬†ï¸  Uploading 7 points to Qdrant (domain=marketing)...
âœ… Uploaded 7 points

ğŸ‰ Sync Complete for MARKETING Domain!
âœ… Success: 3 files
âŒ Errors: 0 files
ğŸ“Š Total points in collection: 11
ğŸ“Š Points for MARKETING domain: 11
```

#### **RÃ©gi Marketing-Specifikus Script (KompatibilitÃ¡s)**

A rÃ©gi `sync_marketing_docs.py` tovÃ¡bbra is mÅ±kÃ¶dik:

```bash
cd backend
python scripts/sync_marketing_docs.py
```

#### **Domain-Specifikus KeresÃ©s ElÅ‘nyei**

**Hibrid KeresÃ©s + Domain SzÅ±rÃ©s:**
- **Szemantikus keresÃ©s**: Vektor hasonlÃ³sÃ¡g (COSINE distance)
- **Domain filter**: Csak az adott domain dokumentumaiban keres
- **KÃ©szenlÃ©t lexikÃ¡lisra**: BM25 support kÃ©szen Ã¡ll (sparse vectors hozzÃ¡adÃ¡sÃ¡val)

**PÃ©lda: HR kÃ©rdÃ©s csak HR dokumentumokban keres**
```python
# Backend automatikusan domain filter-t alkalmaz
query = "szabadsÃ¡g politika"
domain = "hr"  # Intent detection alapjÃ¡n

# Qdrant keresÃ©s domain filter-rel:
filter = {"must": [{"key": "domain", "match": {"value": "hr"}}]}
results = qdrant.search(query_vector=..., query_filter=filter)
# EredmÃ©ny: Csak HR dokumentumok, nem talÃ¡lja a marketing/IT anyagokat
```

**Multi-Domain Collection ElÅ‘nyei:**
- âœ… Egyetlen Qdrant collection az Ã¶sszes domainhez
- âœ… Domain filter index â†’ gyors szÅ±rÃ©s (ms)
- âœ… SkÃ¡lÃ¡zhatÃ³: Ãšj domain hozzÃ¡adÃ¡sa egyszerÅ±
- âœ… KÃ¶zpontosÃ­tottç®¡ç†: Egy helyen az Ã¶sszes tudÃ¡sbÃ¡zis

---

### **8. PÃ©lda: End-to-End Trace**

**User Input:**
```
"Mi a brand guideline sorhossz ajÃ¡nlÃ¡sa?"
```

**1. Intent Detection:**
```
Keyword match: "sorhossz" â†’ marketing domain
```

**2. Query Embedding:**
```
[0.189, -0.623, 0.412, ..., 0.734] (1536 floats)
```

**3. Qdrant Search Results:**
```json
[
  {
    "score": 0.89,
    "payload": {
      "text": "MaximÃ¡lis sorhossz: 70â€“80 karakter.\nMegfelelÅ‘ mennyisÃ©gÅ± Ã¼res tÃ©r alkalmazÃ¡sa.",
      "source_file_name": "Aurora_Digital_Brand_Guidelines_eng.docx",
      "chunk_index": 2
    }
  },
  {
    "score": 0.87,
    "payload": {
      "text": "RÃ¡cs szerkezethez igazÃ­tott elrendezÃ©s.\nFÃ¼ggÅ‘leges ritmus elÅ‘nyben rÃ©szesÃ­tÃ©se.",
      "source_file_name": "Aurora_Digital_Arculati_Kezikonyv_HU.docx",
      "chunk_index": 1
    }
  }
]
```

**4. LLM Context:**
```
Retrieved documents:
[Document 1: Aurora_Digital_Brand_Guidelines_eng.docx]
MaximÃ¡lis sorhossz: 70â€“80 karakter.
MegfelelÅ‘ mennyisÃ©gÅ± Ã¼res tÃ©r alkalmazÃ¡sa.

[Document 2: Aurora_Digital_Arculati_Kezikonyv_HU.docx]
RÃ¡cs szerkezethez igazÃ­tott elrendezÃ©s.
...

User query: "Mi a brand guideline sorhossz ajÃ¡nlÃ¡sa?"
```

**5. Generated Answer:**
```markdown
A brand guideline sorhosszra vonatkozÃ³ javaslat:

### MaximÃ¡lis sorhossz
- **70-80 karakter** a javasolt maximÃ¡lis Ã©rtÃ©k
- MegfelelÅ‘ mennyisÃ©gÅ± Ã¼res tÃ©r alkalmazÃ¡sa kÃ¶telezÅ‘

### ElrendezÃ©s
- RÃ¡cs szerkezethez igazÃ­tott layout
- FÃ¼ggÅ‘leges ritmus elÅ‘nyben rÃ©szesÃ­tÃ©se
```

**6. Frontend Display:**
```
ğŸ¤– Bot vÃ¡lasz: [formatÃ¡lt markdown HTML-lÃ© renderelve]
ğŸ“ ForrÃ¡sok: Aurora_Digital_Brand_Guidelines_eng.docx, Aurora_Digital_Arculati_Kezikonyv_HU.docx
```

---

### **9. Troubleshooting**

**ProblÃ©ma:** "Unknown" forrÃ¡sok jelennek meg
- **Ok:** Frontend cache vagy payload field mapping hiba
- **MegoldÃ¡s:** 
  - EllenÅ‘rizd: `payload.get("source_file_name")` helyes?
  - Cache buster: `<script src="/static/app.js?v=X"></script>`
  - Frontend rebuild: `docker-compose build --no-cache frontend`

**ProblÃ©ma:** Ãœres vagy irrelevÃ¡ns vÃ¡laszok
- **Ok:** Nincs elÃ©g relevÃ¡ns chunk Qdrant-ban
- **MegoldÃ¡s:**
  - Futtasd Ãºjra: `python scripts/sync_marketing_docs.py`
  - EllenÅ‘rizd: `qdrant_client.count(collection_name="marketing")`
  - NÃ¶veld `top_k` Ã©rtÃ©kÃ©t 5-rÅ‘l 10-re

**ProblÃ©ma:** Worker timeout
- **Ok:** TÃºl sok full content az LLM promptban
- **MegoldÃ¡s:** Context truncation (Top 3 full, rest 300 char limit)

---

## ğŸ›¡ï¸ HibakezelÃ©s Ã©s Production Features

### **Automatikus Retry Logika**

A rendszer automatikus retry-t hasznÃ¡l exponenciÃ¡lis backoff-fal OpenAI API hibÃ¡k esetÃ©n:

**HibakezelÃ©s rÃ©tegek:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Input Validation (API)        â”‚
â”‚ - Max 10,000 tokens (~40k chars)       â”‚
â”‚ - HTTP 413 if exceeded                 â”‚
â”‚ - Empty query check                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Prompt Validation (Agent)     â”‚
â”‚ - Max 100,000 tokens                   â”‚
â”‚ - Auto-truncate to top 3 docs          â”‚
â”‚ - Token estimation logging             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: Retry Logic (OpenAI Client)   â”‚
â”‚ - Max 3 retries                        â”‚
â”‚ - Exponential backoff (1s, 2s, 4s)    â”‚
â”‚ - Jitter for thundering herd           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: Model Limit (gpt-4o-mini)     â”‚
â”‚ - 128k context window                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Retry stratÃ©gia:**
- âœ… **RateLimitError (429)**: Retry with `Retry-After` header respect
- âœ… **APITimeoutError**: Retry with exponential backoff
- âœ… **APIConnectionError**: Retry for network issues
- âœ… **Server errors (5xx)**: Retry up to 3 times
- âŒ **Client errors (4xx)**: No retry (immediate fail)
- âŒ **AuthenticationError (401)**: No retry (invalid API key)

**HasznÃ¡lat:**
```python
from infrastructure.error_handling import retry_with_exponential_backoff

@retry_with_exponential_backoff(max_retries=3)
def call_openai_api():
    return client.chat.completions.create(...)
```

### **Token Ã©s KÃ¶ltsÃ©g Tracking**

**Usage Stats Endpoint:**
```bash
# AktuÃ¡lis hasznÃ¡lat lekÃ©rdezÃ©se
curl http://localhost:8001/api/usage-stats/

# Response:
{
  "calls": 127,
  "prompt_tokens": 45200,
  "completion_tokens": 12800,
  "total_tokens": 58000,
  "total_cost_usd": 0.0874  # GPT-4o-mini pricing
}

# StatisztikÃ¡k nullÃ¡zÃ¡sa
curl -X DELETE http://localhost:8001/api/usage-stats/
```

**KÃ¶ltsÃ©g becslÃ©s (GPT-4o-mini per 1M tokens):**
- Input: $0.15
- Output: $0.60
- PÃ©lda: 5k input + 500 output = $0.00105

### **HTTP Status Codes**

A rendszer rÃ©szletes HTTP stÃ¡tusz kÃ³dokat hasznÃ¡l:

| KÃ³d | JelentÃ©s | PÃ©lda |
|-----|----------|-------|
| **200** | Success | Query sikeresen feldolgozva |
| **400** | Bad Request | Ãœres query, validÃ¡ciÃ³s hiba |
| **404** | Not Found | Session vagy file nem lÃ©tezik |
| **413** | Request Too Large | Query >10k tokens (~40k chars) |

### **Request Idempotency (v2.7)** ğŸ†•

A rendszer tÃ¡mogatja az **idempotens request-eket** `X-Request-ID` header hasznÃ¡latÃ¡val. Azonos request ID-val kÃ¼ldÃ¶tt duplikÃ¡lt requestek azonos cached vÃ¡laszt kapnak vissza LLM ÃºjrahÃ­vÃ¡s nÃ©lkÃ¼l.

**MÅ±kÃ¶dÃ©s:**
```
Client: POST /api/query/ (X-Request-ID: abc-123)
        â†“
Server: Redis cache lookup (request_id:abc-123)
        â†“ MISS
Server: LLM processing â†’ Save to cache (TTL: 5 min)
        â†“
Client: Response { "success": true, "data": {...} }

Client: POST /api/query/ (X-Request-ID: abc-123) [DUPLICATE]
        â†“
Server: Redis cache HIT â†’ Return cached response
        â†“
Client: Response (X-Cache-Hit: true) [< 10ms latency]
```

**Cache kulcs:** `request_id:{uuid}`  
**TTL:** 5 perc (300s)  
**ElÅ‘nyÃ¶k:** KÃ¶ltsÃ©gcsÃ¶kkentÃ©s (duplikÃ¡lt LLM hÃ­vÃ¡sok elkerÃ¼lÃ©se), instant vÃ¡lasz, network retry protection

**PÃ©lda hasznÃ¡lat:**
```bash
# Generate UUID v4 client-oldalon
REQUEST_ID=$(uuidgen)

# First request - processzÃ¡lÃ¡s
curl -X POST http://localhost:8001/api/query/ \
  -H "Content-Type: application/json" \
  -H "X-Request-ID: $REQUEST_ID" \
  -d '{"query": "Mi a szabadsÃ¡g policy?", "user_id": "demo"}'

# Duplicate request - cached response
curl -X POST http://localhost:8001/api/query/ \
  -H "X-Request-ID: $REQUEST_ID" \
  -d '{"query": "Mi a szabadsÃ¡g policy?", "user_id": "demo"}'
# Response headers: X-Cache-Hit: true
```

**KompatibilitÃ¡s:** Nem Ã¼tkÃ¶zik a `/api/regenerate/` endpoint-tal (kÃ¼lÃ¶nbÃ¶zÅ‘ cache kulcsok).

### **Memory Reducer Pattern (v2.7)** ğŸ†•

A konverzÃ¡ciÃ³s memÃ³ria **kumulatÃ­v Ã¶sszefoglalÃ³** rendszert hasznÃ¡l szemantikus tÃ¶mÃ¶rÃ­tÃ©ssel:

**StratÃ©gia:**
```
Previous Summary (8 msgs) + New Messages (8 msgs)
                â†“ LLM Merge
        Updated Summary (3-5 sentences)
                â†“ Semantic Compression
        8 MOST RELEVANT Facts
```

**MÅ±kÃ¶dÃ©s (pÃ©lda):**
```python
# Turn 1 (8 messages)
memory_summary: "User wants marketing HR meeting. Budget: 50k."
memory_facts: ["Budget: 50,000 Ft", "Meeting date: 2026-01-20", "Team lead: Anna"]

# Turn 2 (8 new messages) - User: "Actually 60k budget"
# LLM merges previous + new
memory_summary: "User plans marketing HR meeting. Budget updated to 60k. Needs approval."
memory_facts: [
  "Budget: 60,000 Ft",  # Recent overwrites old (50k â†’ 60k)
  "Meeting date: 2026-01-20",  # Still relevant
  "Approval required from CFO"  # New fact
  # "Team lead: Anna" dropped (not mentioned anymore)
]
```

**Semantic Compression Rules:**
- âœ… **Merge similar facts**: `"user wants X" + "user needs X"` â†’ `"user requires X"`
- âœ… **Prioritize recent**: Conflicts resolved by recency (newest wins)
- âœ… **Keep constraints**: Dates, names, numbers preserved
- âœ… **Drop irrelevant**: Facts no longer relevant to conversation direction

**KonfigurÃ¡ciÃ³:**
- `MEMORY_MAX_MESSAGES=8` - Rolling window size (default: 8)
- Max facts: 8 (compressed from prev_facts + new_messages)
- Non-blocking: Memory update failures nem akadÃ¡lyozzÃ¡k a vÃ¡laszt

**Log output:**
```
Memory updated (REDUCER): 6 facts (compressed from 13 items), 
summary length: 342 chars, total messages: 24
```
| **500** | Internal Server Error | Backend exception |
| **503** | Service Unavailable | OpenAI API down vagy timeout |

### **Input Validation**

**Query mÃ©ret vÃ©delem:**
```python
# views.py
query_text = request.data.get("query", "")

# 1. Empty check
if not query_text.strip():
    return Response({"error": "Query cannot be empty"}, status=400)

# 2. Token limit check (10k tokens)
try:
    check_token_limit(query_text, max_tokens=10000)
except ValueError:
    return Response(
        {"error": "Query too long. Max 10,000 tokens (~40k chars)"},
        status=413
    )
```

**PÃ©lda tÃºl nagy query blokkolÃ¡sa:**
```bash
# 54k karakteres query
curl -X POST http://localhost:8001/api/query/ \
  -H "Content-Type: application/json" \
  -d '{"query": "very long text..." * 2000}'

# Response: HTTP 413
{
  "error": "Query is too long. Please shorten your question to under 10,000 tokens (~40,000 characters)."
}
```

### **Logging Ã©s Monitoring**

**StrukturÃ¡lt logging minden rÃ©tegen:**
```python
# Intent detection
logger.info(f"Detected domain: {domain}")

# Retrieval
logger.info(f"Retrieved {len(citations)} documents from Qdrant (domain={domain})")

# Token tracking
logger.info(f"Prompt size: ~{estimate_tokens(prompt)} tokens")

# Error handling
logger.warning(f"Rate limited (attempt {attempt}/3). Waiting {wait_time:.1f}s...")
logger.error(f"Query too long: {estimated} tokens (max: {max_tokens})")
```

**Log pÃ©lda:**
```
2025-12-17 08:14:31 INFO QueryAgent: Detected domain: marketing
2025-12-17 08:14:32 INFO QdrantRAGClient: Retrieved 5 docs (domain=marketing)
2025-12-17 08:14:32 INFO QueryAgent: Prompt size: ~3200 tokens
2025-12-17 08:14:33 INFO error_handling: API call #127: 3200 + 450 tokens, cost: $0.000750
```

---

## ğŸ” BiztonsÃ¡g & Compliance

âœ… **Citations**: Minden vÃ¡lasz tartalmazza a forrÃ¡s dokumentum ID-jÃ¡t  
âœ… **Audit Log**: Teljes conversation history mentÃ©se  
âœ… **Reset Context**: Special command a beszÃ©lgetÃ©si elÅ‘zmÃ©nyek tÃ¶rlÃ©sÃ©re  
âœ… **User Profiles**: Soha nem tÃ¶rlÅ‘dnek, csak frissÃ­thetÅ‘k  

## ğŸ› ï¸ FejlesztÃ©s

### Local Dev (BASH/WSL)

```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate  # vagy venv\Scripts\activate (Windows)
pip install -r requirements.txt
export OPENAI_API_KEY="sk-..."
python manage.py runserver 0.0.0.0:8000

# Frontend (Ãºj terminal)
cd frontend
npx http-server . -p 3000
```

### Docker Dev

```bash
docker-compose up --build
# Changes are auto-reloaded (gunicorn --reload)
```

## ğŸ› ï¸ FejlesztÅ‘i EszkÃ¶zÃ¶k (v2.2)

### Health Check Rendszer

Az alkalmazÃ¡s indÃ­tÃ¡skor automatikusan validÃ¡lja az infrastruktÃºrÃ¡t:

```bash
docker-compose up
```

**PÃ©lda kimenet:**
```
======================================================================
ğŸ¥ INFRASTRUCTURE HEALTH CHECK
======================================================================

ğŸ“Œ CRITICAL SERVICES:
  âœ… ENV:OPENAI_API_KEY=sk-proj-***
  âœ… OpenAI client importable
  âœ… Qdrant URL configured: http://qdrant:6333

ğŸ“‹ OPTIONAL SERVICES:
  âš ï¸ PostgreSQL will use lazy init: postgres
  âš ï¸ Redis configured: redis://redis:6379

======================================================================
âœ… ALL CRITICAL SERVICES READY
======================================================================
```

**FunkciÃ³k:**
- âœ… Fail-fast kritikus szolgÃ¡ltatÃ¡sok hiÃ¡nyÃ¡ban
- âš ï¸ Graceful degradation opcionÃ¡lis szolgÃ¡ltatÃ¡soknÃ¡l
- ğŸ” API key maszkolÃ¡s biztonsÃ¡gi okokbÃ³l
- ğŸ“Š Visual health report startup-nÃ¡l

### Debug CLI

InteraktÃ­v RAG tesztelÃ©s fejlesztÃ©s kÃ¶zben:

```bash
# Python REPL
docker-compose exec backend python
>>> from utils.debug_cli import quick_search
>>> import asyncio
>>> asyncio.run(quick_search('brand colors', 'marketing', 5))

# Parancssor
docker-compose exec backend python -m utils.debug_cli "szabadsÃ¡g igÃ©nylÃ©s" hr 5
```

**PÃ©lda kimenet:**
```
ğŸ“š RETRIEVED 3 CITATIONS:
================================================================================

  [1] Score: 1.3000 | ID: 1ACEdQxgUuAsDHKPBqKyp2kt88DjfXjhv#chunk0
      Title: Aurora_Digital_Brand_Guidelines_eng.docx
      Content: "Brand colors are #0066CC (primary blue)..."

ğŸ“Š FEEDBACK STATISTICS (3 citations):

### ğŸ” Telemetria Debug Panel (Frontend)

**Real-time observability** a frontend-en (jobb alsÃ³ sarokban):

**MegjelenÃ­tett metrikÃ¡k:**
- â±ï¸ **Pipeline Latency** - Teljes kÃ©rÃ©s-vÃ¡lasz idÅ‘ (ms)
- ğŸ“¦ **Chunk Count** - Visszaadott RAG dokumentumok szÃ¡ma
- ğŸ¯ **Max Similarity Score** - Legmagasabb relevancia Ã©rtÃ©k
- ğŸ“¤ **Request JSON** - KÃ¼ldÃ¶tt payload (collapsible)
- ğŸ“¥ **Response JSON** - Teljes API vÃ¡lasz (collapsible)
- ğŸ” **RAG Context** - LLM-nek kÃ¼ldÃ¶tt dokumentumok (collapsible)
- ğŸ¤– **LLM Prompt** - Teljes LLM prompt (collapsible)
- ğŸ’¬ **LLM Response** - Raw LLM vÃ¡lasz (collapsible)

**HasznÃ¡lat:**
1. Nyisd meg a frontend-et: http://localhost:3000
2. A jobb alsÃ³ sarokban lÃ¡sd a debug panel-t
3. Minden kÃ©rdÃ©s utÃ¡n automatikusan frissÃ¼l
4. Kattints a rÃ©szletekre a collapsible szekciÃ³k kibontÃ¡sÃ¡hoz
5. A panel scrollozhatÃ³ (max 85vh)

**Mikor hasznÃ¡ld:**
- ğŸ› Debug - LLM prompt engineering
- ğŸ“Š Performance - Latency monitoring
- ğŸ”¬ RAG analysis - Chunk quality validation
- ğŸ§ª Testing - End-to-end pipeline inspection
================================================================================

  ğŸŸ¢  85.0% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘] doc_123#chunk0
  ğŸŸ¡  55.0% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] doc_456#chunk1
  ğŸ”´  25.0% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] doc_789#chunk2
```

**FunkciÃ³k:**
- ğŸ“ Citation formÃ¡zÃ¡s (score, metadata, content preview)
- ğŸ“Š Feedback statisztika bar chart-okkal
- ğŸ”„ Semantic vs feedback-boosted ranking Ã¶sszehasonlÃ­tÃ¡s
- ğŸ¯ SzÃ­nkÃ³dolt feedback indikÃ¡torok (ğŸŸ¢ğŸŸ¡ğŸ”´)

### Unit Tesztek

```bash
# Ã–sszes teszt futtatÃ¡sa coverage-el
docker-compose exec backend pytest tests/ --cov=infrastructure --cov=domain --cov=utils --cov-report=html

# Specifikus test suite-ok
docker-compose exec backend pytest tests/test_health_check.py -v
docker-compose exec backend pytest tests/test_debug_cli.py -v
docker-compose exec backend pytest tests/test_interfaces.py -v
docker-compose exec backend pytest tests/test_feedback_ranking.py -v

# HTML coverage report megtekintÃ©se
# Nyisd meg: backend/htmlcov/index.html
```

**Teszt EredmÃ©nyek:**
- âœ… **121/136 teszt Ã¡tmegy** (89% success rate)
- ğŸ“Š **49% code coverage** (megduplÃ¡zva a 25%-os baseline-hoz kÃ©pest)
- ğŸ†• **36 Ãºj teszt** az Ãºj architektÃºra komponensekhez
- ğŸ¯ **Teszt kategÃ³riÃ¡k**: Health Checks (10), Debug CLI (17), Interfaces (15), Feedback Ranking (14)

### SOLID ArchitektÃºra

Az Ãºj v2.2 verziÃ³ ABC interfÃ©szeket hasznÃ¡l a jobb tesztelhetÅ‘sÃ©gÃ©rt Ã©s swappable implementÃ¡ciÃ³kÃ©rt:

```python
# InterfÃ©szek domain/interfaces.py-ban
from domain.interfaces import IEmbeddingService, IVectorStore, IFeedbackStore, IRAGClient

# KÃ¶nnyÅ± mock-olÃ¡s tesztekben
class MockEmbeddingService(IEmbeddingService):
    def get_embedding(self, text): return [0.1, 0.2, 0.3]
    def is_available(self): return True

# Type-safe implementations
client: IRAGClient = QdrantRAGClient(...)
```

**ElÅ‘nyÃ¶k:**
- ğŸ§ª KÃ¶nnyÅ± mock-olÃ¡s unit tesztekben
- ğŸ”„ Swappable implementÃ¡ciÃ³k (Qdrant â†’ Pinecone/Weaviate)
- ğŸ“ VilÃ¡gos contract minden komponenshez
- âœ… Dependency Inversion Principle kÃ¶vetÃ©se

---

## ğŸ“š KapcsolÃ³dÃ³ Dokumentumok

### Projekt DokumentÃ¡ciÃ³
- [Installation Guide](INSTALLATION.md) - RÃ©szletes telepÃ­tÃ©si ÃºtmutatÃ³
- [Features](docs/FEATURES.md) - FunkciÃ³k rÃ©szletes leÃ­rÃ¡sa, architektÃºra diagramok
- [API Documentation](docs/API.md) - REST API endpoints, request/response pÃ©ldÃ¡k
- [Tasks](docs/tasks/1.md) - Projekt feladatok Ã©s mÃ©rfÃ¶ldkÃ¶vek

### InfrastruktÃºra & IntegrÃ¡ciÃ³
- [Redis Cache Architecture](docs/REDIS_CACHE.md) - Cache stratÃ©gia, invalidÃ¡lÃ¡s, monitoring
- [Google Drive Setup](docs/GOOGLE_DRIVE_SETUP.md) - Drive API konfigurÃ¡ciÃ³, OAuth setup
- [Frontend Setup](docs/FRONTEND_SETUP.md) - Tailwind CSS, Nginx, build folyamat

### Testing & Development
- [Test README](backend/tests/README.md) - Unit teszt dokumentÃ¡ciÃ³, coverage reports
- [Init Prompt](docs/INIT_PROMPT.md) - Kezdeti projekt prompt Ã©s kÃ¶vetelmÃ©nyek

### RepÃ³-szintÅ± DokumentÃ¡ciÃ³
- [LangGraph Usage (Repo)](../ai_agent_complex/docs/LANGGRAPH_USAGE_HU.md)
- [Agent Loop (Repo)](../ai_agent_complex/docs/AGENT_LOOP_HU.md)
- [Architecture (Repo)](../ai_agent_complex/docs/ARCHITECTURE.md)

## ğŸ¤ Roadmap

### âœ… ElkÃ©szÃ¼lt (v2.4)
- [x] **LangGraph StateGraph orchestration** (4 nodes: intent â†’ retrieval â†’ generation â†’ workflow)
- [x] **Multi-domain Qdrant collection** (6 domain: HR, IT, Finance, Legal, Marketing, General)
- [x] **Confluence/Jira API integration** (IT Policy auto-sync, section ID tracking) ğŸ†•
- [x] **Google Drive API integration** (marketing docs auto-sync)
- [x] **Redis L1/L2 cache** (embedding + query result, 54% hit rate)
- [x] **PostgreSQL feedback system** (like/dislike, batch ops, lazy init) ğŸ†•
- [x] **Content deduplication** (PDF/DOCX signature-based, title normalization) ğŸ†•
- [x] **IT domain overlap boost** (lexical token matching, 0-20% boost) ğŸ†•
- [x] **Feedback-weighted ranking** (tiered boost: >70% +30%, <40% -20%) ğŸ†•
- [x] **Section ID citations** (IT-KB-XXX format, parser inheritance) ğŸ†•
- [x] **Cache invalidation** (sync scripts auto-clear Redis)
- [x] **Token tracking & cost calculation** (retry logic, exponential backoff)
- [x] **Comprehensive testing** (180 tests, 53% coverage) ğŸ†•
  - Unit tests: deduplication (9), IT boost (11), feedback (4), error handling (39)
  - Integration tests: RAG pipeline (6), feedback (3), health checks (10)
  - Coverage highlights: openai_clients 100%, qdrant_rag_client 70%, atlassian_client 87%
- [x] **Multi-domain workflows** (HR szabadsÃ¡g, IT ticket) - LangGraph workflow node
- [x] **SOLID architektÃºra** (ABC interfaces, DIP compliance)
- [x] **Health check rendszer** (startup validation: OpenAI, Qdrant, Redis, Postgres)
- [x] **Debug CLI** (visual RAG testing tools, citation formatting)
- [x] **Telemetry debug panel** (RAG context, LLM prompt/response, pipeline latency)

### ğŸš§ KÃ¶vetkezÅ‘ Sprint (v2.5 - Performance)
- [ ] **Performance benchmarks** (deduplication overhead, cache hit ratios)
- [ ] **Coverage improvement** (53% â†’ 60% target)
  - postgres_client: 44% â†’ 60%
  - redis_client: 58% â†’ 75%
- [ ] **BM25 hybrid search** (sparse vectors for exact match on section IDs, brand names)
- [ ] **Multi-query generation** (query expansion with frequency ranking)
- [ ] **A/B testing framework** (IT overlap boost tuning: 10% vs 15% vs 20%)

### ğŸ”® Backlog (Future Releases)
- [ ] **Frontend feedback UI v2** (thumbs up/down visible, feedback stats dashboard)
- [ ] **Monitoring & observability** (Prometheus metrics, Grafana dashboards)
- [ ] **Advanced integration tests** (E2E multi-domain RAG flows)
- [ ] **Slack integration** (chatbot for Slack workspace)
- [ ] **PII detection** (automatic masking of sensitive data)
- [ ] **Rate limiting** (per-user: 100 req/hour, per-org: 10k req/day)
- [ ] **Advanced caching** (semantic cache with embedding similarity)
- [ ] **Fuzzy deduplication** (Levenshtein distance for near-duplicates)
- [ ] **Citation click-through tracking** (implicit feedback collection)
- [ ] **Auto-reindexing triggers** (feedback threshold-based)
- [ ] **Frontend React version** (optional SPA migration)

## ğŸ“ Support

Ha kÃ©rdÃ©sed van, nyisd meg az issue-t vagy nÃ©zd meg a `docs/` mappÃ¡t.

---

**Happy Knowledge Routing! ğŸš€**
#   T e s t   c o m m i t   f o r   G i t H u b   A c t i o n s   -   2 0 2 6 - 0 2 - 0 4   2 0 : 3 7  
 