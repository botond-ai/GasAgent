# ğŸ“– RAG Agent - Quick Reference

**Production-ready RAG alkalmazÃ¡s dokumentum-alapÃº AI asszisztenssel**

## âœ… Status

- **Tests**: âœ… 42/42 PASSING (100%)
- **Error Handling**: âœ… 5 patterns + 19 tests
- **Deployment**: âœ… Docker + local dev ready

---

## ğŸš€ Quick Start (2 perc)

### 1. Setup Environment
```bash
cd /Users/tothgabor/ai-agents-hu/mini_projects/gabor.toth
cp .env.example .env
# Add OPENAI_API_KEY to .env
```

### 2. Start Application
```bash
# Option A: Recommended (local dev)
source .env && ./start-dev.sh

# Option B: Docker
docker-compose up --build

# Frontend: http://localhost:5173
# Backend: http://localhost:8000
```

---

## ğŸ¯ Core Features

| Feature | Description | Status |
|---------|-------------|--------|
| **ğŸ“„ File Upload** | Markdown, TXT, PDF support with categories | âœ… |
| **ğŸ¤– AI Routing** | LLM-based category selection | âœ… |
| **ğŸ” RAG Search** | Vector + keyword (hybrid) search | âœ… |
| **ğŸ’¬ Chat** | Multi-turn with conversation history | âœ… |
| **ğŸ“‹ Activity Logger** | Real-time process tracking | âœ… |
| **ğŸ’¾ Persistence** | JSON-based user profiles & sessions | âœ… |
| **ğŸ”„ Error Recovery** | 5 resilience patterns | âœ… |

---

## ğŸ”Œ Main API Endpoints

### Chat & Files
```
POST   /api/chat              # Ask question
POST   /api/files/upload      # Upload document
GET    /api/activities        # Activity logs
```

### Admin
```
GET    /api/health            # Server status
POST   /api/cat-match         # Category detection
POST   /api/desc-save         # Save category description
GET    /api/dev-logs          # Feature tracking logs
```

---

## ğŸ“Š Test Coverage

```bash
# Run all 42 tests
python3 -m pytest backend/tests/test_working_agent.py -v

# Quick summary
python3 -m pytest backend/tests/test_working_agent.py --tb=no
```

**Breakdown:**
- Core Workflow: 23 tests âœ…
- Conversation Cache: 7 tests âœ…
- **Error Handling**: 19 tests âœ…
  - Guardrail Node: 6
  - Fail-Safe Recovery: 4
  - Retry with Backoff: 5
  - Fallback Model: 1
  - Planner Fallback: 3

---

## ğŸ“ Project Structure

```
gabor.toth/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ langgraph_workflow.py  # LangGraph (11 nodes)
â”‚   â”‚   â””â”€â”€ chat_service.py        # Chat orchestration
â”‚   â”œâ”€â”€ infrastructure/      # DB, embeddings, routing
â”‚   â”œâ”€â”€ domain/              # SOLID interfaces
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_working_agent.py  # 42 comprehensive tests
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main component
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â””â”€â”€ api.ts           # HTTP client
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ users/               # User profiles (JSON)
â”‚   â”œâ”€â”€ sessions/            # Chat history (JSON)
â”‚   â””â”€â”€ chroma_db/           # Vector database
â”‚
â””â”€â”€ DOCUMENTATION/
    â”œâ”€â”€ ERROR_HANDLING_*.md   # Error handling docs
    â”œâ”€â”€ QUICK_START.md
    â””â”€â”€ FULL_README.md       # Complete documentation
```

---

## ğŸ”§ Configuration

### Environment Variables
```bash
OPENAI_API_KEY=sk-...        # Required
DEVELOPMENT=true              # Optional
```

### Retrieval Thresholds
Edit `backend/services/langgraph_workflow.py`:
```python
SEMANTIC_THRESHOLD = 0.45     # Minimum semantic score
CONTENT_THRESHOLD = 150       # Minimum content length
```

---

## ğŸ§  How It Works

```
1. User asks question â†’ Input validation
2. Category routing â†’ LLM picks best category
3. Vector search â†’ Find relevant chunks
4. Quality check â†’ Verify search results
5. Reranking â†’ LLM scores relevance
6. Hybrid search (optional) â†’ Combine semantic + BM25
7. Answer generation â†’ LLM creates response with citations
8. Checkpoint â†’ Save workflow state
9. Return â†’ Send answer + metadata to frontend
```

---

## ğŸ“Š Performance

- **Test Execution**: 1.21 seconds
- **Query Processing**: 150-450ms
- **Memory Usage**: ~120-160MB typical
- **Pass Rate**: 100% (42/42 tests)

---

## ğŸ› Error Handling

Application implements 5 production-ready patterns:

1. **Guardrail Node** - Input validation & quality gates
2. **Fail-Safe Recovery** - Error detection & smart retry
3. **Retry with Backoff** - Exponential backoff (1sâ†’2sâ†’4s)
4. **Fallback Model** - Simplified answer generation
5. **Planner Fallback** - Search quality evaluation

See [ERROR_HANDLING_TESTS_SUMMARY.md](./DOCUMENTATION/ERROR_HANDLING_TESTS_SUMMARY.md) for details.

---

## ğŸš€ Deployment

### Docker Compose
```bash
docker-compose up --build
```

### Production Notes
- Requires OpenAI API key
- Uses ChromaDB for vector storage
- JSON-based persistence (no external DB needed)
- Supports horizontal scaling with shared data volume

---

## ğŸ“š Documentation

- **[FULL_README.md](./FULL_README.md)** - Complete documentation
- **[QUICK_START.md](./QUICK_START.md)** - Feature guide
- **[LANGGRAPH_QUICKSTART.md](./LANGGRAPH_QUICKSTART.md)** - LangGraph 101
- **[ERROR_HANDLING_TESTS_SUMMARY.md](./DOCUMENTATION/ERROR_HANDLING_TESTS_SUMMARY.md)** - Error handling details

---

## â“ Common Tasks

### Add New Document Category
```bash
# 1. Upload document with new category
# 2. LLM automatically detects and creates category
# 3. Start asking questions in that category
```

### Debug Chat Response
Check `rag_debug` field in API response:
- `retrieved` - Which chunks were used
- `debug_steps` - Workflow step timeline
- `api_info` - Performance metrics

### Check Server Health
```bash
curl http://localhost:8000/api/health
```

---

**Built with**: FastAPI â€¢ React â€¢ LangGraph â€¢ OpenAI â€¢ ChromaDB  
**Status**: Production-Ready âœ…  
**Last Updated**: 2026-01-27
